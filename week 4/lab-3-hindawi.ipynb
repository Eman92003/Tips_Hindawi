{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14404986,"sourceType":"datasetVersion","datasetId":9200140},{"sourceId":14405364,"sourceType":"datasetVersion","datasetId":9200377},{"sourceId":14405414,"sourceType":"datasetVersion","datasetId":9200413}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install langchain langchain-community langchain-core faiss-cpu pypdf sentence-transformers transformers==4.52.4","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T19:36:49.741696Z","iopub.execute_input":"2026-01-05T19:36:49.742138Z","iopub.status.idle":"2026-01-05T19:37:14.713323Z","shell.execute_reply.started":"2026-01-05T19:36:49.742104Z","shell.execute_reply":"2026-01-05T19:37:14.712610Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\nCollecting langchain-community\n  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\nRequirement already satisfied: langchain-core in /usr/local/lib/python3.12/dist-packages (0.3.79)\nCollecting faiss-cpu\n  Downloading faiss_cpu-1.13.2-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (7.6 kB)\nRequirement already satisfied: pypdf in /usr/local/lib/python3.12/dist-packages (6.4.2)\nRequirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.1)\nCollecting transformers==4.52.4\n  Downloading transformers-4.52.4-py3-none-any.whl.metadata (38 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.52.4) (3.20.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.52.4) (0.36.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.52.4) (2.0.2)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.52.4) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.52.4) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.52.4) (2025.11.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.52.4) (2.32.5)\nCollecting tokenizers<0.22,>=0.21 (from transformers==4.52.4)\n  Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers==4.52.4) (0.6.2)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.52.4) (4.67.1)\nRequirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\nRequirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.37)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.5)\nCollecting SQLAlchemy<3,>=1.4 (from langchain)\n  Downloading sqlalchemy-2.0.45-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (9.5 kB)\nINFO: pip is looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\nCollecting langchain-community\n  Downloading langchain_community-0.4-py3-none-any.whl.metadata (3.0 kB)\n  Downloading langchain_community-0.3.31-py3-none-any.whl.metadata (3.0 kB)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.2)\nRequirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (8.5.0)\nRequirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.7)\nRequirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.11.0)\nRequirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\nRequirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (1.33)\nRequirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (4.15.0)\nRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\nRequirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.15.3)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.52.4) (2025.10.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.52.4) (1.2.1rc0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\nRequirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (3.11.3)\nRequirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\nRequirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.25.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\nRequirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.5)\nRequirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\nRequirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.52.4) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.52.4) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.52.4) (2.6.2)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.52.4) (2025.11.12)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\nRequirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\nRequirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.3)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\nRequirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.12.0)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\nDownloading transformers-4.52.4-py3-none-any.whl (10.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n\u001b[?25hDownloading langchain_community-0.3.31-py3-none-any.whl (2.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading faiss_cpu-1.13.2-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (23.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m96.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading sqlalchemy-2.0.45-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (3.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m76.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: SQLAlchemy, faiss-cpu, tokenizers, transformers, langchain-community\n  Attempting uninstall: SQLAlchemy\n    Found existing installation: SQLAlchemy 1.2.19\n    Uninstalling SQLAlchemy-1.2.19:\n      Successfully uninstalled SQLAlchemy-1.2.19\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.22.1\n    Uninstalling tokenizers-0.22.1:\n      Successfully uninstalled tokenizers-0.22.1\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.57.1\n    Uninstalling transformers-4.57.1:\n      Successfully uninstalled transformers-4.57.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nxmanager 0.7.1 requires sqlalchemy==1.2.19, but you have sqlalchemy 2.0.45 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed SQLAlchemy-2.0.45 faiss-cpu-1.13.2 langchain-community-0.3.31 tokenizers-0.21.4 transformers-4.52.4\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from langchain.output_parsers import StructuredOutputParser, ResponseSchema\nfrom langchain.prompts import PromptTemplate\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nfrom langchain.output_parsers import StructuredOutputParser, ResponseSchema\nimport torch\nimport re\nfrom langchain.document_loaders import PyPDFLoader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T19:37:30.381724Z","iopub.execute_input":"2026-01-05T19:37:30.382139Z","iopub.status.idle":"2026-01-05T19:37:43.264692Z","shell.execute_reply.started":"2026-01-05T19:37:30.382098Z","shell.execute_reply":"2026-01-05T19:37:43.263907Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"model_name = \"mistralai/Mistral-Nemo-Instruct-2407\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, device_map=\"auto\")\n\ndef generate_text(prompt, max_length=1000, num_return_sequences=1):\n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n    outputs = model.generate(\n        **inputs,\n        max_length=max_length,\n        num_return_sequences=num_return_sequences,\n        do_sample=True,\n        top_k=50,\n        top_p=0.95,\n        temperature=0.7,\n    )\n    return [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T19:37:49.785004Z","iopub.execute_input":"2026-01-05T19:37:49.785484Z","iopub.status.idle":"2026-01-05T19:42:52.855081Z","shell.execute_reply.started":"2026-01-05T19:37:49.785455Z","shell.execute_reply":"2026-01-05T19:42:52.854194Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8be7bf68b534e0591084f6d5f01dd58"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"086fae68be0c46e98ccabc2f009de2d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a27dd7296c4b40538e2ac3dc76428286"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/622 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"161b13bb23c54a58a83f99d11f66ce47"}},"metadata":{}},{"name":"stderr","text":"2026-01-05 19:38:00.798769: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1767641881.236721      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1767641881.354250      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1767641882.407557      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767641882.407593      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767641882.407596      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767641882.407598      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac675548d6e945b1a823d0e6bc555fcc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"509ece685ad64287abc97e028f2edb74"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00005.safetensors:   0%|          | 0.00/4.87G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5518ff59657e441eb4e09ff557a1fdd5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00005.safetensors:   0%|          | 0.00/4.91G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"381be6ab3c58414aaabb52ad9cc0a129"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00005.safetensors:   0%|          | 0.00/4.91G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"051e69b7ea144572adffe745cdd55313"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00005-of-00005.safetensors:   0%|          | 0.00/4.91G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3bfdf7a85464647a677790baab8170c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00005.safetensors:   0%|          | 0.00/4.91G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83bcba086ab0406f803a4303eb19e37a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6fd9fd08b58486c9bb734452819b8ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be4f76a5d84847bfa017c3f9f1a6c2db"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"##Extract CV\n\nCV_path = \"/kaggle/input/cv-file/Eman Yaser Rezk_CV.pdf\"\nloader = PyPDFLoader(CV_path)\nDocument = loader.load()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T19:42:57.296622Z","iopub.execute_input":"2026-01-05T19:42:57.297276Z","iopub.status.idle":"2026-01-05T19:42:57.811676Z","shell.execute_reply.started":"2026-01-05T19:42:57.297247Z","shell.execute_reply":"2026-01-05T19:42:57.811068Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"final_text = \"\\n\".join([doc.page_content for doc in Document])\nprint(final_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T19:54:12.931907Z","iopub.execute_input":"2026-01-05T19:54:12.932766Z","iopub.status.idle":"2026-01-05T19:54:12.937309Z","shell.execute_reply.started":"2026-01-05T19:54:12.932730Z","shell.execute_reply":"2026-01-05T19:54:12.936546Z"}},"outputs":[{"name":"stdout","text":"Eman Yaser Rezk \nemanyaserr2003@gmail.com   |   01096052095    |   Mansoura, Egypt |  LinkedIn  |   GitHub \n \nSUMMARY \nComputer Science graduate with a solid background in artificial intelligence, machine learning, and \nsoftware development. Dedicated to using technical skills to solve problems and create effective \nsolutions. Seeking a job opportunity to apply my skills, contribute to innovative projects, and grow within \na dynamic team. \n \nEDUCATION \n Bachelor of Computer Science \n Faculty of Computer and Information Sciences, Mansoura University \n• GPA score: 4 out of 4, Excellent with honors, Overall percentage: 93.56%. \n \nTRAINING \nTrainee| National Telecommunication Institute (NTI)  \n• Python programming basics.  \n• Artificial Intelligence foundations.  \n• Mathematical Foundations for Deep Learning. \n• Introduction to Deep Learning & TensorFlow.  \nTrainee| Information Technology Institute (ITI)  \n• Python, NumPy, Probability, Statistics, and Linear Algebra for ML. \n• Data Preparation and Exploration.  \n• Supervised and Unsupervised Machine Learning.  \n• Introduction to Deep Learning.   \n \nCOURSES \n• Advanced Learning Algorithms | Coursera  \n• Supervised Machine Learning: Regression and Classification | Coursera  \n• Computer Vision | Kaggle  \n• Intro to Deep Learning | Kaggle  \n• Applied Deep Learning | Mahara-Tech  \n• Python Programming Basics | Mahara-Tech  \n• Database Fundamentals | Mahara-Tech \n \nPROJECTS \nAncient Aura | Graduation Project (A) \n• Developed a recommendation system using collaborative filtering with multilabel encoding and \ncosine similarity to suggest historical sites based on user preferences. \n• Built and trained a Convolutional Neural Network model to classify Egyptian landmarks from  \nuser-uploaded images. \n• Implemented an AI-powered chatbot based on a Retrieval-Augmented Generation (RAG) system to \nprovide historically accurate answers about Ancient Egypt. \n• Developed and deployed a user-friendly mobile application for seamless system interaction. \nTechnologies: Python, TensorFlow, Scikit-learn, Keras, LangChain, Flask, FastAPI, Hugging Face. \n \n \n \nOct 2021 – Jul 2025  \nMansoura, Egypt \nAug 2024 – Sep 2024 \nOnline \nJul 2024 – Aug 2024 \nHybrid\nGreenGo | Multi-Class Classification of Garbage Using Deep Learning \n• Applied transfer learning with ResNet50 to develop a convolutional neural network, achieving 97% \naccuracy in classifying garbage images into 12 categories. \n• Used FastAPI to test and deploy the model.  \n• Used Streamlit to create a simple interface.  \nTechnologies: Python, TensorFlow, Keras, Scikit-learn, NumPy, FastAPI, Streamlit. \n \nHateGuard | Arabic Hate Speech Detection \n• Preprocessed Arabic text by removing diacritics, punctuation, and unwanted characters, applying \nstopword elimination, normalization, tokenization, and lemmatization. \n• Developed and trained a Bidirectional LSTM deep learning model, achieving 78% accuracy. \n• Applied Early Stopping and ReduceLROnPlateau to optimize training and prevent overfitting. \nTechnologies: Python, Keras, NumPy, Bidirectional LSTM, EarlyStopping, ReduceLROnPlateau. \n \nLEADERSHIP & COMMUNITY INVOLVEMENT \nBionic Team | Data Science Committee Head  \nTaught fundamental data science concepts, including Python, data analysis,  \nand machine learning. \n \nCIS Team MU | Graphics Committee Head  \nAssigned tasks for members, reviewed their work, provided assessments,                                                            \nand organized online meetings to track progress. \n \nSKILLS \n• Programming Languages: Python, C#, HTML, CSS, Dart  \n• Data Structures and Algorithms: Greedy, Divide and Conquer, Huffman, Sorting algorithms, Tree, \nList, Dictionary, Heap, and Graph data structures.  \n• Frameworks & Libraries: Flutter, Pandas, NumPy, Matplotlib, Seaborn, TensorFlow, Keras.  \n• Soft Skills: Leadership, Teamwork, Research, Presentation Skills. \n \nLANGUAGES \nEnglish: B2 | British Council      Arabic | Native \nOct 2024 – Jun 2025 \nDec 2023 – Aug 2024\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"name_schema = ResponseSchema(\n    name = \"full_name\",\n    description = \"Full name of the Candidate as mentioned in the documnet\"\n)\n\nemail_schema = ResponseSchema(\n    name = \"email\",\n    description = \"The Candidate's email in the document\"\n)\n\neducation_schema = ResponseSchema(\n    name = \"Education\",\n    description = \"list of information about candidate education, the earned degree, the institution, and graduation year\"\n)\n\nskills_schema = ResponseSchema(\n    name = \"Skills\",\n    description = \"list of soft and technical skills mentioned in the candidate CV\"\n)\n\nexperience_schema = ResponseSchema(\n    name = \"Experience\",\n    description = \"list of candidate's experiences: what is his role, where does he work, and for how many years\"\n)\n\nresponse_schema = [name_schema,email_schema,education_schema,skills_schema,experience_schema]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T19:48:19.181978Z","iopub.execute_input":"2026-01-05T19:48:19.182563Z","iopub.status.idle":"2026-01-05T19:48:19.187076Z","shell.execute_reply.started":"2026-01-05T19:48:19.182532Z","shell.execute_reply":"2026-01-05T19:48:19.186226Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"output_parser = StructuredOutputParser.from_response_schemas(response_schema)\nformat_instructions = output_parser.get_format_instructions()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T19:48:26.927826Z","iopub.execute_input":"2026-01-05T19:48:26.928296Z","iopub.status.idle":"2026-01-05T19:48:26.933654Z","shell.execute_reply.started":"2026-01-05T19:48:26.928261Z","shell.execute_reply":"2026-01-05T19:48:26.932802Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"print(format_instructions)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T19:48:27.295144Z","iopub.execute_input":"2026-01-05T19:48:27.295434Z","iopub.status.idle":"2026-01-05T19:48:27.299675Z","shell.execute_reply.started":"2026-01-05T19:48:27.295408Z","shell.execute_reply":"2026-01-05T19:48:27.298923Z"}},"outputs":[{"name":"stdout","text":"The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n\n```json\n{\n\t\"full_name\": string  // Full name of the Candidate as mentioned in the documnet\n\t\"email\": string  // The Candidate's email in the document\n\t\"Education\": string  // list of information about candidate education, the earned degree, the institution, and graduation year\n\t\"Skills\": string  // list of soft and technical skills mentioned in the candidate CV\n\t\"Experience\": string  // list of candidate's experiences: what is his role, where does he work, and for how many years\n}\n```\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"type(format_instructions)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T20:04:48.657798Z","iopub.execute_input":"2026-01-05T20:04:48.658117Z","iopub.status.idle":"2026-01-05T20:04:48.663175Z","shell.execute_reply.started":"2026-01-05T20:04:48.658090Z","shell.execute_reply":"2026-01-05T20:04:48.662423Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"str"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"purchase_extraction_template = \"\"\"\nYou are a smart assistant that extracts Candidate information from the CV sent to the HR.\n\nExtract the candidate name, email, education, skills and previous experience.\n\nRespond ONLY in JSON format as follows:\n{format_instructions}\n\nExample Input:\n'''\nJohn Smith – john.smith@email.com\nEducation: B.Sc. Computer Science, MIT, 2020\nSkills: Python, Machine Learning, Data Analysis\nExperience:\n- Software Engineer at Google (2020–2023)\n- Data Scientist at OpenAI (2023–Present)\n'''\n\nNow extract from the following input:\n\"{user_input}\"\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T19:51:55.352245Z","iopub.execute_input":"2026-01-05T19:51:55.352878Z","iopub.status.idle":"2026-01-05T19:51:55.356958Z","shell.execute_reply.started":"2026-01-05T19:51:55.352846Z","shell.execute_reply":"2026-01-05T19:51:55.356160Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"user_input = final_text\n\nprompt = PromptTemplate(\n    template=purchase_extraction_template,\n    input_variables=[\"user_input\", \"format_instructions\"]\n).format(user_input=user_input, format_instructions=format_instructions)\n\nresponse = generate_text(prompt, max_length=3000)[0]\nprint(response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T19:54:49.654238Z","iopub.execute_input":"2026-01-05T19:54:49.654868Z","iopub.status.idle":"2026-01-05T19:55:08.645808Z","shell.execute_reply.started":"2026-01-05T19:54:49.654837Z","shell.execute_reply":"2026-01-05T19:55:08.645009Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\nYou are a smart assistant that extracts Candidate information from the CV sent to the HR.\n\nExtract the candidate name, email, education, skills and previous experience.\n\nRespond ONLY in JSON format as follows:\nThe output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n\n```json\n{\n\t\"full_name\": string  // Full name of the Candidate as mentioned in the documnet\n\t\"email\": string  // The Candidate's email in the document\n\t\"Education\": string  // list of information about candidate education, the earned degree, the institution, and graduation year\n\t\"Skills\": string  // list of soft and technical skills mentioned in the candidate CV\n\t\"Experience\": string  // list of candidate's experiences: what is his role, where does he work, and for how many years\n}\n```\n\nExample Input:\n'''\nJohn Smith – john.smith@email.com\nEducation: B.Sc. Computer Science, MIT, 2020\nSkills: Python, Machine Learning, Data Analysis\nExperience:\n- Software Engineer at Google (2020–2023)\n- Data Scientist at OpenAI (2023–Present)\n'''\n\nNow extract from the following input:\n\"Eman Yaser Rezk \nemanyaserr2003@gmail.com   |   01096052095    |   Mansoura, Egypt |  LinkedIn  |   GitHub \n \nSUMMARY \nComputer Science graduate with a solid background in artificial intelligence, machine learning, and \nsoftware development. Dedicated to using technical skills to solve problems and create effective \nsolutions. Seeking a job opportunity to apply my skills, contribute to innovative projects, and grow within \na dynamic team. \n \nEDUCATION \n Bachelor of Computer Science \n Faculty of Computer and Information Sciences, Mansoura University \n• GPA score: 4 out of 4, Excellent with honors, Overall percentage: 93.56%. \n \nTRAINING \nTrainee| National Telecommunication Institute (NTI)  \n• Python programming basics.  \n• Artificial Intelligence foundations.  \n• Mathematical Foundations for Deep Learning. \n• Introduction to Deep Learning & TensorFlow.  \nTrainee| Information Technology Institute (ITI)  \n• Python, NumPy, Probability, Statistics, and Linear Algebra for ML. \n• Data Preparation and Exploration.  \n• Supervised and Unsupervised Machine Learning.  \n• Introduction to Deep Learning.   \n \nCOURSES \n• Advanced Learning Algorithms | Coursera  \n• Supervised Machine Learning: Regression and Classification | Coursera  \n• Computer Vision | Kaggle  \n• Intro to Deep Learning | Kaggle  \n• Applied Deep Learning | Mahara-Tech  \n• Python Programming Basics | Mahara-Tech  \n• Database Fundamentals | Mahara-Tech \n \nPROJECTS \nAncient Aura | Graduation Project (A) \n• Developed a recommendation system using collaborative filtering with multilabel encoding and \ncosine similarity to suggest historical sites based on user preferences. \n• Built and trained a Convolutional Neural Network model to classify Egyptian landmarks from  \nuser-uploaded images. \n• Implemented an AI-powered chatbot based on a Retrieval-Augmented Generation (RAG) system to \nprovide historically accurate answers about Ancient Egypt. \n• Developed and deployed a user-friendly mobile application for seamless system interaction. \nTechnologies: Python, TensorFlow, Scikit-learn, Keras, LangChain, Flask, FastAPI, Hugging Face. \n \n \n \nOct 2021 – Jul 2025  \nMansoura, Egypt \nAug 2024 – Sep 2024 \nOnline \nJul 2024 – Aug 2024 \nHybrid\nGreenGo | Multi-Class Classification of Garbage Using Deep Learning \n• Applied transfer learning with ResNet50 to develop a convolutional neural network, achieving 97% \naccuracy in classifying garbage images into 12 categories. \n• Used FastAPI to test and deploy the model.  \n• Used Streamlit to create a simple interface.  \nTechnologies: Python, TensorFlow, Keras, Scikit-learn, NumPy, FastAPI, Streamlit. \n \nHateGuard | Arabic Hate Speech Detection \n• Preprocessed Arabic text by removing diacritics, punctuation, and unwanted characters, applying \nstopword elimination, normalization, tokenization, and lemmatization. \n• Developed and trained a Bidirectional LSTM deep learning model, achieving 78% accuracy. \n• Applied Early Stopping and ReduceLROnPlateau to optimize training and prevent overfitting. \nTechnologies: Python, Keras, NumPy, Bidirectional LSTM, EarlyStopping, ReduceLROnPlateau. \n \nLEADERSHIP & COMMUNITY INVOLVEMENT \nBionic Team | Data Science Committee Head  \nTaught fundamental data science concepts, including Python, data analysis,  \nand machine learning. \n \nCIS Team MU | Graphics Committee Head  \nAssigned tasks for members, reviewed their work, provided assessments,                                                            \nand organized online meetings to track progress. \n \nSKILLS \n• Programming Languages: Python, C#, HTML, CSS, Dart  \n• Data Structures and Algorithms: Greedy, Divide and Conquer, Huffman, Sorting algorithms, Tree, \nList, Dictionary, Heap, and Graph data structures.  \n• Frameworks & Libraries: Flutter, Pandas, NumPy, Matplotlib, Seaborn, TensorFlow, Keras.  \n• Soft Skills: Leadership, Teamwork, Research, Presentation Skills. \n \nLANGUAGES \nEnglish: B2 | British Council      Arabic | Native \nOct 2024 – Jun 2025 \nDec 2023 – Aug 2024\"\n```json\n{\n\t\"full_name\": \"Eman Yaser Rezk\",\n\t\"email\": \"emanyaserr2003@gmail.com\",\n\t\"Education\": \"Bachelor of Computer Science, Faculty of Computer and Information Sciences, Mansoura University\",\n\t\"Skills\": \"Python, C#, HTML, CSS, Dart, Pandas, NumPy, Matplotlib, Seaborn, TensorFlow, Keras, Leadership, Teamwork, Research, Presentation Skills\",\n\t\"Experience\": \"Trainee at National Telecommunication Institute (NTI), Trainee at Information Technology Institute (ITI)\"\n}\n```\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"def extract_json_block(text):\n    pattern = r'```json\\s*(.*?)\\s*```'\n    matches = re.findall(pattern, text, re.DOTALL)\n\n    return f\"```json\\n{matches[-1]}\\n```\"\n\njson_text = extract_json_block(response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T19:56:09.970700Z","iopub.execute_input":"2026-01-05T19:56:09.971451Z","iopub.status.idle":"2026-01-05T19:56:09.975562Z","shell.execute_reply.started":"2026-01-05T19:56:09.971421Z","shell.execute_reply":"2026-01-05T19:56:09.974842Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"output_data = output_parser.parse(json_text)\nprint(output_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T19:56:28.774373Z","iopub.execute_input":"2026-01-05T19:56:28.774694Z","iopub.status.idle":"2026-01-05T19:56:28.782706Z","shell.execute_reply.started":"2026-01-05T19:56:28.774652Z","shell.execute_reply":"2026-01-05T19:56:28.781940Z"}},"outputs":[{"name":"stdout","text":"{'full_name': 'Eman Yaser Rezk', 'email': 'emanyaserr2003@gmail.com', 'Education': 'Bachelor of Computer Science, Faculty of Computer and Information Sciences, Mansoura University', 'Skills': 'Python, C#, HTML, CSS, Dart, Pandas, NumPy, Matplotlib, Seaborn, TensorFlow, Keras, Leadership, Teamwork, Research, Presentation Skills', 'Experience': 'Trainee at National Telecommunication Institute (NTI), Trainee at Information Technology Institute (ITI)'}\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"arabic_path = \"/kaggle/input/arabic-cv/Eman Yaser Arabic CV.pdf\"\nloader = PyPDFLoader(arabic_path)\nDocument_arabic = loader.load()\narabic_text = \"\\n\".join([doc.page_content for doc in Document_arabic])\nprint(arabic_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T20:44:44.625722Z","iopub.execute_input":"2026-01-05T20:44:44.626351Z","iopub.status.idle":"2026-01-05T20:44:45.291646Z","shell.execute_reply.started":"2026-01-05T20:44:44.626318Z","shell.execute_reply":"2026-01-05T20:44:45.290957Z"}},"outputs":[{"name":"stdout","text":"ﻣﺼﺮ  ،\u0000ﺼﻮرە\u0000اﻟﻤ\u0000  :\u0000 ﻪ\u0000\u0000\u0000اﻟﻤﺪ\u0000| 01096052095: \u0000\u0000\u0000اﻟﻬﺎ| emanyaserr2003@gmail.com: \u0000ﯽ\u0000ﺮو\u0000\u0000ﻟﻜ\u0000ٕا\u0000\u0000  ﺪ\u0000ﺮ\u0000\u0000اﻟ\u0000|\nLinkedIn | GitHub\n\u0000ﻪ\u0000\u0000\u0000\u0000\u0000\u0000\u0000اﻟ\u0000  \u0000ﯽ\u0000ﻣﻬﺎرا\u0000  ﺪام\u0000ﺤ\u0000\u0000\u0000ﺳ\u0000  \u0000ﻣﻜﺮﺳﻪ.  \u0000ﺎٮ\u0000\u0000\u0000 ﺮﻣﺤ\u0000اﻟ\u0000  ﺮ\u0000ﻄﻮ\u0000\u0000و\u0000  \u0000ﻟﯽٓا\u0000\u0000  ﻌﻠﻢ\u0000واﻟ\u0000  \u0000ﺎﻋﯽ\u0000ا\u0000\u0000ﺻﻄ\u0000  ﻛﺎء\u0000اﻟﺪ  \u0000ﯽ\u0000\u0000  \u0000ﻪ\u0000ﻮ\u0000\u0000\u0000  \u0000ﻪ\u0000\u0000\u0000ﻠ\u0000\u0000ﺤ\u0000\u0000  \u0000ﺎٮ\u0000اﻟﺤﺎﺳ\u0000  ﻋﻠﻮم  \u0000ﻪ\u0000ﺤ\u0000ﺮ\u0000\u0000ﺣ\n\u0000 ﻤﮟ\u0000 ﺻ  ﻤﻮ\u0000واﻟ\u0000  \u0000ﻜﺮە\u0000\u0000\u0000ﻣ\u0000  ﻊ\u0000ﺎر\u0000\u0000ﻣﺴ  \u0000ﯽ\u0000\u0000  \u0000واﻟﻤﺴﺎﻫﻤﻪ  \u0000ﯽ\u0000ﻣﻬﺎرا\u0000  \u0000\u0000\u0000\u0000\u0000ﻄ\u0000\u0000ﻟ\u0000  ﻋﻤﻞ  \u0000ﺮﺻﻪ\u0000\u0000  ﻋﻠﯽ  ﻟﻠﺤﺼﻮل  ﺳﻌﯽٔا.  \u0000ﻌﺎﻟﻪ\u0000\u0000  ﺣﻠﻮل  ﺎء\u0000ﺴ\u0000\u0000ٕوا  ﺎﻛﻞ\u0000اﻟﻤﺴ  ﻟﺤﻞ\n\u0000ﻜﯽ\u0000ﺎﻣ\u0000\u0000\u0000\u0000د\u0000  \u0000\u0000\u0000ﺮ\u0000\u0000\u0000.\n\u0000 ﺎٮ\u0000اﻟﺤﺎﺳ\u0000  ﻋﻠﻮم  \u0000ﯽ\u0000\u0000  ﻮس\u0000ﻜﺎﻟﻮر\u0000\u0000\u0000\n\u0000ﺼﻮرە\u0000اﻟﻤ\u0000  \u0000ﺎﻣﻌﻪ\u0000 ﺣ  ،\u0000ﻪ\u0000ﻋ\u0000\u0000ﻣ\u0000ٕا\u0000\u0000  واﻟﻌﻠﻮم  \u0000ﺎٮ\u0000اﻟﺤﺎﺳ\u0000  \u0000ﻪ\u0000ﻛﻠ\u0000\n\u0000 ﺮڡ\u0000اﻟﺴ  \u0000ﻪ\u0000\u0000\u0000ﻤﺮ\u0000\u0000\u0000  \u0000ﺎر\u0000ﻣﻤ\u0000  ،4 \u0000ﻣﮟ  4 : \u0000ﺮاﻛﻤﯽ\u0000\u0000  ﻣﻌﺪل\n93.56 : \u0000ﻪ\u0000ﻤﺎﻟ\u0000\u0000 ﺣٕا\u0000\u0000  \u0000ﻪ\u0000ﺴ\u0000\u0000اﻟ\u0000%\n2025 ﻮ\u0000ﻮﻟ\u0000\u0000\u0000 –  2021 ﺮ\u0000ﻮ\u0000\u0000ﻛ\u0000ٔا:  \u0000ﺮە\u0000\u0000\u0000اﻟ\u0000\n\u0000 ﺼﺎ\u0000\u0000ٮ\u0000ﻟ\u0000\u0000\u0000  \u0000ﻮﻣﯽ\u0000اﻟ\u0000  اﻟﻤﻌﻬﺪ| \u0000ﺪرٮ\u0000ﻣ\u0000NTI)\n\u0000ﻪ\u0000ﻠﻌ\u0000\u0000  \u0000ﻪ\u0000ﺮﻣﺤ\u0000اﻟ\u0000  \u0000ﺎٮ\u0000ﺳﺎﺳ\u0000ٔاPython\n\u0000ﺎﻋﯽ\u0000ا\u0000\u0000ﺻﻄ\u0000  ﻛﺎء\u0000اﻟﺪ  \u0000ﺎٮ\u0000ﺳﺎﺳ\u0000ٔا\n\u0000 \u0000\u0000اﻟﻌﻤ\u0000  ﻌﻠﻢ\u0000ﻟﻠ\u0000  \u0000ﻪ\u0000\u0000\u0000 ﺎﺻ\u0000اﻟﺮ\u0000  ﺳﺲٔا\u0000\u0000\nو  \u0000\u0000\u0000اﻟﻌﻤ\u0000  ﻌﻠﻢ\u0000اﻟ\u0000  \u0000ﯽ\u0000\u0000  \u0000ﺪﻣﻪ\u0000ﻣ\u0000TensorFlow\n2024 ﺮ\u0000ﻤ\u0000\u0000\u0000\u0000ﺳ\u0000 –  ﺴﻄﺲ\u0000ﻋٔا:  \u0000ﺮە\u0000\u0000\u0000اﻟ\u0000\n\u0000 اﻟﻤﻌﻠﻮﻣﺎٮ  ﺎ\u0000\u0000\u0000ﻮﻟﻮﺣ\u0000ﻜ\u0000\u0000\u0000  ﻣﻌﻬﺪ| \u0000ﺪرٮ\u0000ﻣ\u0000ITI)\nPython وNumPy \u0000ﻟﯽٓا\u0000\u0000  ﻌﻠﻢ\u0000ﻟﻠ\u0000  \u0000ﻄﯽ\u0000اﻟﺤ  ﺮ\u0000\u0000\u0000 واﻟﺤ  \u0000ﺎٮ\u0000\u0000ٔﺣﺼﺎ\u0000ٕوا\u0000\u0000  \u0000ﻤﺎ\u0000\u0000ٮ\u0000وا\u0000\u0000ﺣ\u0000\n\u0000 ﺎٮ\u0000ﺎ\u0000\u0000\u0000\u0000اﻟ\u0000  \u0000ﺎڡ\u0000ﻜﺴ\u0000واﺳ\u0000  ﺮ\u0000\u0000\u0000 ﺤﺼ\u0000\u0000\nﻪ\u0000اﻟﻤﻮﺣ  ﺮ\u0000\u0000\u0000وﻋ  ﻪ\u0000اﻟﻤﻮﺣ  \u0000ﻟﯽٓا\u0000\u0000  ﻌﻠﻢ\u0000اﻟ\u0000\n\u0000 \u0000\u0000اﻟﻌﻤ\u0000  ﻌﻠﻢ\u0000اﻟ\u0000  \u0000ﯽ\u0000\u0000  \u0000ﺪﻣﻪ\u0000ﻣ\u0000\n2024 ﺴﻄﺲ\u0000ﻋٔا –  ﻮ\u0000ﻮﻟ\u0000\u0000\u0000:  \u0000ﺮە\u0000\u0000\u0000اﻟ\u0000\n\u0000 ٯ\u0000رر  ﺎﺳﺮ\u0000\u0000  \u0000ﻤﺎں\u0000\u0000ٕا\n\u0000ﺼﯽ\u0000ﺤ\u0000اﻟﺴ  ﺺ\u0000اﻟﻤﻠﺤ\n\u0000ﻪ\u0000ﻤ\u0000\u0000ﻌﻠ\u0000\u0000اﻟ\u0000  \u0000ﻫ\u0000\u0000ٮٔاﻟﻤﻮ\n\u0000ﻪ\u0000\u0000\u0000اﻟﻤﻬ\u0000  \u0000ﻬﺎداٮ\u0000واﻟﺴ  \u0000\u0000\u0000ﺪر\u0000\u0000اﻟ\u0000\n2025 ﻮ\u0000\u0000\u0000ﻮ\u0000\u0000\u0000 –  2024 ﺮ\u0000ﻮ\u0000\u0000ﻛ\u0000ٔا  :\u0000 ﺮە\u0000\u0000\u0000اﻟ\u0000\n\u0000ﺪﻣﻪ\u0000ﺤ\u0000اﻟﻤﺴ\u0000  \u0000ﺎٮ\u0000\u0000\u0000\u0000\u0000\u0000\u0000اﻟ\u0000:Python, TensorFlow, Scikit-learn, Keras, LangChain, Flask, FastAPI, Hugging\nFace\n2024 ﺴﻄﺲ\u0000ﻋٔا –  2023 ﺮ\u0000ﺴﻤ\u0000\u0000د\u0000  :\u0000 ﺮە\u0000\u0000\u0000اﻟ\u0000\n\u0000ﺪﻣﻪ\u0000ﺤ\u0000اﻟﻤﺴ\u0000  \u0000ﺎٮ\u0000\u0000\u0000\u0000\u0000\u0000\u0000اﻟ\u0000:Python, TensorFlow, Keras, Scikit-learn, NumPy, FastAPI, Streamlit\n2024 ﺴﻄﺲ\u0000ﻋٔا –  2023 ﺮ\u0000ﺴﻤ\u0000\u0000د\u0000  :\u0000 ﺮە\u0000\u0000\u0000اﻟ\u0000\n\u0000ﮟ\u0000\u0000\u0000\u0000\u0000و\u0000ٔا\u0000\u0000  \u0000ﻬﺎداٮ\u0000واﻟﺴ  \u0000اﻟﺪوراٮ\n\u0000ﺪﻣﻪ\u0000\u0000\u0000اﻟﻤ\u0000  ﻌﻠﻢ\u0000اﻟ\u0000  \u0000ﺎٮ\u0000ﻣ\u0000\u0000ﻮارر\u0000ﺣ| Coursera•\n \u0000\u0000\u0000\u0000\u0000ﺼ\u0000واﻟ\u0000  ﺤﺪار\u0000ا\u0000\u0000\u0000:  ﻪ\u0000اﻟﻤﻮﺣ  \u0000ﻟﯽٓا\u0000\u0000  ﻌﻠﻢ\u0000اﻟ\u0000| Coursera•\n \u0000اﻟﺤﺎﺳﻮٮ  \u0000ﻪ\u0000\u0000ٔرو| Kaggle•\n \u0000\u0000\u0000اﻟﻌﻤ  ﻌﻠﻢ\u0000اﻟ\u0000  \u0000ﯽ\u0000\u0000  \u0000ﺪﻣﻪ\u0000ﻣ\u0000| Kaggle•\n\u0000ﯽ\u0000\u0000\u0000\u0000\u0000ﻄ\u0000\u0000اﻟ\u0000  \u0000\u0000\u0000اﻟﻌﻤ\u0000  ﻌﻠﻢ\u0000اﻟ\u0000| Mahara-Tech•\nـ\u0000\u0000  \u0000ﻪ\u0000ﺮﻣﺤ\u0000اﻟ\u0000  \u0000ﺎٮ\u0000ﺳﺎﺳ\u0000ٔاPython | Mahara-Tech•\n \u0000ﺎٮ\u0000ﺎ\u0000\u0000\u0000\u0000اﻟ\u0000  ﻮاﻋﺪ\u0000\u0000  \u0000ﺎٮ\u0000ﺳﺎﺳ\u0000ٔا| Mahara-Tech•\nﻊ\u0000ﺎر\u0000\u0000 اﻟﻤﺴ\nAncient Aura | \u0000ﺮح\u0000ﺤ\u0000اﻟ\u0000  ﺮوع\u0000ﻣﺴA)\n\u0000ﻪ\u0000ﺮ\u0000\u0000\u0000ٔا  ﻊ\u0000ﻣﻮا\u0000  ﺮاح\u0000\u0000\u0000\u0000\u0000\u0000  ﻤﺎم\u0000اﻟ\u0000  \u0000\u0000\u0000\u0000\u0000 ﺣ  ﻪ\u0000ﺎ\u0000\u0000ﺴ\u0000و\u0000  اﻟﻮﺳﻮم  ﻌﺪد\u0000ﻣ\u0000  \u0000ﺮ\u0000ﺮﻣ\u0000\u0000\u0000  ﻣﻊ  \u0000ﻪ\u0000\u0000\u0000ﻌﺎو\u0000\u0000اﻟ\u0000  \u0000ﻪ\u0000\u0000\u0000ﺼ\u0000\u0000اﻟ\u0000  ﺪام\u0000ﺤ\u0000ﺎﺳ\u0000\u0000\u0000  \u0000ﺎٮ\u0000ﻮﺻ\u0000\u0000\u0000  ﺎم\u0000 ﻄ\u0000\u0000  \u0000ﻃﻮرٮ\nﺪم\u0000ﺤ\u0000اﻟﻤﺴ\u0000  \u0000\u0000\u0000ٮ\u0000\u0000\u0000 ﺼ\u0000\u0000\u0000\u0000  ﻋﻠﯽ  ًﺎء\u0000\u0000\u0000\u0000.\n•\n\u0000ﻪ\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000  \u0000ﻪ\u0000\u0000\u0000ﻋﺼ\u0000  \u0000ﻜﻪ\u0000\u0000\u0000ﺳ  \u0000ح\u0000ﻤﻮد\u0000\u0000  \u0000\u0000\u0000ﺪر\u0000\u0000و\u0000  ﺎء\u0000\u0000\u0000\u0000CNN) ﺪم\u0000ﺤ\u0000اﻟﻤﺴ\u0000  ﻞ\u0000\u0000\u0000\u0000  \u0000ﻣﮟ  \u0000ﻮﻋﻪ\u0000اﻟﻤﺮ\u0000  اﻟﺼﻮر  \u0000ﻣﮟ  \u0000ﻪ\u0000اﻟﻤﺼﺮ\u0000  اﻟﻤﻌﺎﻟﻢ  \u0000\u0000\u0000\u0000\u0000ﺼ\u0000\u0000ﻟ\u0000.•\nﺎم\u0000 ﻄ\u0000\u0000  ﺪام\u0000ﺤ\u0000ﺎﺳ\u0000\u0000\u0000  \u0000ﺎﻋﯽ\u0000ا\u0000\u0000ﺻﻄ\u0000  ﻛﺎء\u0000ﺎﻟﺪ\u0000\u0000  ﻣﺪﻋﻮم  \u0000ﻪ\u0000ﻣﺤﺎد\u0000  \u0000ﻮٮ\u0000رو\u0000  \u0000\u0000\u0000\u0000\u0000ﻄ\u0000\u0000\u0000Retrieval-Augmented Generation\n(RAG) \u0000ﻤﻪ\u0000ﺪ\u0000\u0000اﻟ\u0000  ﻣﺼﺮ  \u0000ﻋﮟ  ًﺎ\u0000\u0000\u0000ﺤ\u0000ﺎر\u0000\u0000\u0000  \u0000ﻪ\u0000\u0000\u0000\u0000\u0000د\u0000  \u0000ﺎٮ\u0000ﺎ\u0000\u0000 ﺣٕا  ﻢ\u0000ﺪ\u0000\u0000\u0000\u0000ﻟ\u0000.\n•\nﺎم\u0000 ﻄ\u0000اﻟ\u0000  ﻣﻊ  اﻟﺴﻠﺲ  ﺎﻋﻞ\u0000\u0000\u0000ﻟﻠ\u0000  ﺪام\u0000ﺤ\u0000ا\u0000\u0000ﺳ\u0000  ﺳﻬﻞ  ﻮال\u0000ﺣ  \u0000\u0000\u0000\u0000\u0000ﻄ\u0000\u0000\u0000  ﺮ\u0000ﺴ\u0000و\u0000  ﺮ\u0000ﻄﻮ\u0000\u0000\u0000.•\nGreenGo | \u0000\u0000\u0000اﻟﻌﻤ  ﻌﻠﻢ\u0000اﻟ\u0000  ﺪام\u0000ﺤ\u0000ﺎﺳ\u0000\u0000\u0000  \u0000ﺎٮٔ\u0000\u0000اﻟ\u0000  ﻌﺪد\u0000ﻣ\u0000  \u0000ﻤﺎﻣﻪ\u0000اﻟ\u0000  \u0000\u0000\u0000\u0000\u0000ﺼ\u0000\u0000\u0000\nﺪام\u0000ﺤ\u0000ﺎﺳ\u0000\u0000\u0000  ﻞ\u0000\u0000\u0000ﺎﻟ\u0000\u0000\u0000  ﻌﻠﻢ\u0000اﻟ\u0000  \u0000\u0000\u0000\u0000\u0000ﻄ\u0000\u0000\u0000ResNet50 ﺻﻮر  \u0000\u0000\u0000\u0000\u0000ﺼ\u0000\u0000\u0000  \u0000ﯽ\u0000\u0000%  97 \u0000ﻪ\u0000د\u0000  \u0000\u0000\u0000\u0000\u0000ﺣ\u0000  \u0000\u0000\u0000ﺣ\u0000  ،\u0000ﻪ\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000  \u0000ﻪ\u0000\u0000\u0000ﻋﺼ\u0000  \u0000ﻜﻪ\u0000\u0000\u0000ﺳ  ﺮ\u0000ﻄﻮ\u0000\u0000ﻟ\u0000\n\u0000ﻪٔ\u0000\u0000\u0000  12 ﻟﯽٕا  \u0000ﻤﺎﻣﻪ\u0000اﻟ\u0000.\n•\nﺪام\u0000ﺤ\u0000اﺳ\u0000FastAPI \u0000ح\u0000ﻤﻮد\u0000اﻟ\u0000  \u0000\u0000\u0000\u0000\u0000ﻄ\u0000\u0000و\u0000  ﺎر\u0000\u0000\u0000\u0000\u0000\u0000\u0000ﺣ.•\nﺪام\u0000ﺤ\u0000اﺳ\u0000Streamlit \u0000ﻄﻪ\u0000ﺴ\u0000\u0000\u0000  \u0000ﻬﻪ\u0000واﺣ  ﺎء\u0000ﺴ\u0000\u0000ٕ\u0000\u0000.•\nHateGuard | \u0000ﻪ\u0000\u0000\u0000اﻟﻌﺮ\u0000  \u0000ﻪ\u0000ﺎﻟﻠﻌ\u0000\u0000  \u0000ﻪ\u0000اﻟﻜﺮاﻫ\u0000  \u0000ﻄﺎٮ\u0000ﺣ  \u0000ﻋﮟ  \u0000\u0000\u0000اﻟﻜﺴ\nﻊ\u0000\u0000\u0000ﻄ\u0000\u0000واﻟ\u0000  \u0000ﻌﻪٔﺎ\u0000\u0000اﻟﺴ  \u0000اﻟﻜﻠﻤﺎٮ  \u0000اﻟﻪ\u0000رٕا  \u0000\u0000\u0000\u0000\u0000ﻄ\u0000\u0000\u0000  ﻣﻊ  ،\u0000ﻪ\u0000ﻮ\u0000\u0000اﻟﻤﺮﻋ  ﺮ\u0000\u0000\u0000ﻋ  \u0000ﺣﺮڡٔوا\u0000\u0000  \u0000واﻟﻌ\u0000\u0000ﻣﺎٮ  ﻞ\u0000ﻜ\u0000\u0000ﺴ\u0000اﻟ\u0000  \u0000اﻟﻪ\u0000رٕﺎ\u0000\u0000  \u0000ﻪ\u0000\u0000\u0000اﻟﻌﺮ\u0000  ﺼﻮص\u0000اﻟ\u0000  \u0000ﻪ\u0000ﻣﻌﺎﻟﺤ\n\u0000ﻮى\u0000اﻟﻠﻌ  ﻞ\u0000ﺤﻠ\u0000\u0000واﻟ\u0000  \u0000ﺮ\u0000ﺮﻣ\u0000\u0000واﻟ\u0000.\n•\n\u0000 ح\u0000ﻤﻮد\u0000\u0000  \u0000\u0000\u0000ﺪر\u0000\u0000و\u0000  ﺮ\u0000ﻄﻮ\u0000\u0000\u0000LSTM ﺎە\u0000 ﺤ\u0000ا\u0000\u0000\u0000  \u0000ﯽٔﺎ\u0000\u0000\u0000\u0000\u0000Bidirectional LSTM)،  78 \u0000ﻪ\u0000د\u0000  \u0000\u0000\u0000ﺣ\u0000  \u0000\u0000\u0000ﺣ\u0000.%•\n\u0000ﺪﻣﻪ\u0000ﺤ\u0000اﻟﻤﺴ\u0000  \u0000ﺎٮ\u0000\u0000\u0000\u0000\u0000\u0000\u0000اﻟ\u0000:Python, Keras, NumPy, Bidirectional LSTM, EarlyStopping,\nReduceLROnPlateau\nBionic Team | \u0000ﺎٮ\u0000ﺎ\u0000\u0000\u0000\u0000اﻟ\u0000  ﻋﻠﻮم  \u0000ﻪ\u0000\u0000\u0000ﻟﺤ  ﺲ\u0000\u0000ٔر\u0000\nﻬﺎ\u0000\u0000\u0000\u0000  ﻤﺎ\u0000\u0000  ،\u0000ﺎٮ\u0000ﺎ\u0000\u0000\u0000\u0000اﻟ\u0000  ﻟﻌﻠﻮم  \u0000ﻪ\u0000ﺳﺎﺳ\u0000ٔا\u0000\u0000  ﻢ\u0000ﺎﻫ\u0000\u0000اﻟﻤ\u0000  ﺲ\u0000ﺪر\u0000\u0000\u0000Python \u0000ﻟﯽٓا\u0000\u0000  ﻌﻠﻢ\u0000واﻟ\u0000  \u0000ﺎٮ\u0000ﺎ\u0000\u0000\u0000\u0000اﻟ\u0000  ﻞ\u0000ﺤﻠ\u0000\u0000و\u0000\n2025 ﻮ\u0000\u0000\u0000ﻮ\u0000\u0000\u0000 –  2024 ﺮ\u0000ﻮ\u0000\u0000ﻛ\u0000ٔا:  \u0000ﺮە\u0000\u0000\u0000اﻟ\u0000\nCIS Team MU | \u0000ﺎٮ\u0000اﻟﺮﺳﻮﻣ\u0000  \u0000ﻪ\u0000\u0000\u0000ﻟﺤ  ﺲ\u0000\u0000ٔر\u0000\nﺪم\u0000\u0000\u0000اﻟ\u0000  ﻊ\u0000\u0000\u0000\u0000\u0000ﻟ\u0000  \u0000ﮟ\u0000\u0000\u0000\u0000\u0000و\u0000ٔا\u0000\u0000  \u0000ﻤﺎﻋﺎٮ\u0000\u0000\u0000 ا\u0000\u0000ﺣ  ﻢ\u0000\u0000\u0000 ﻄ\u0000\u0000\u0000و\u0000  \u0000ﻤﺎٮ\u0000\u0000\u0000\u0000\u0000\u0000\u0000اﻟ\u0000  ﻢ\u0000ﺪ\u0000\u0000\u0000\u0000\u0000  ﻋﻤﺎﻟﻬﻢ،ٔا  \u0000ﻌﻪ\u0000 ﻣﺮاﺣ  ﺎء،\u0000 ﻋﺼٔﻟ\u0000\u0000  اﻟﻤﻬﺎم  \u0000ﮟ\u0000\u0000\u0000ﻌ\u0000\u0000\u0000\n2024 ﺴﻄﺲ\u0000ﻋٔا –  2023 ﺮ\u0000ﺴﻤ\u0000\u0000د\u0000:  \u0000ﺮە\u0000\u0000\u0000اﻟ\u0000\nPython, C#, HTML, CSS, Dart\nGreedy, Divide and Conquer, Hu\u0000man, \u0000ﺮر\u0000اﻟ\u0000  \u0000ﺎٮ\u0000ﻣ\u0000\u0000ﻮارر\u0000ﺣ،Tree, List, Dictionary, Heap, Graph\nFlutter, Pandas, NumPy, Matplotlib, Seaborn, TensorFlow, Keras\nﻢ\u0000ﺪ\u0000\u0000\u0000\u0000واﻟ\u0000  \u0000اﻟﻌﺮص  \u0000ﻣﻬﺎراٮ  ،\u0000اﻟﻌﻠﻤﯽ  \u0000ﺤ\u0000\u0000اﻟ\u0000  ،\u0000ﻤﺎﻋﯽ\u0000 اﻟﺤ  اﻟﻌﻤﻞ  ،\u0000ﺎدە\u0000\u0000\u0000اﻟ\u0000\nﻜﺮ\u0000اﻟﻤ\u0000  \u0000\u0000\u0000ﻮ\u0000\u0000اﻟ\u0000  \u0000\u0000\u0000\u0000\u0000ﻄ\u0000\u0000\u0000Early Stopping) وReduceLROnPlateau \u0000ﯽ\u0000\u0000  ﺮاط\u0000\u0000ٕا\u0000\u0000  ﻊ\u0000وﻣ\u0000  \u0000\u0000\u0000ﺪر\u0000\u0000اﻟ\u0000  \u0000ﮟ\u0000ﺤﺴ\u0000\u0000ﻟ\u0000\n\u0000 \u0000\u0000ﺪر\u0000\u0000اﻟ\u0000.\n•\n\u0000ﻪ\u0000ﻤﻌ\u0000\u0000\u0000\u0000اﻟﻤﺤ  \u0000ﺎرﻛﻪ\u0000 واﻟﻤﺴ  \u0000ﺎدە\u0000\u0000\u0000اﻟ\u0000\n\u0000 اﻟﻤﻬﺎراٮ\n\u0000ﻪ\u0000ﺮﻣﺤ\u0000اﻟ\u0000  \u0000ﺎٮ\u0000ﻟﻌ\n\u0000 ﺎٮ\u0000ﻣ\u0000\u0000ﻮارر\u0000واﻟﺤ  \u0000ﺎٮ\u0000ﺎ\u0000\u0000\u0000\u0000اﻟ\u0000  ﺎﻛﻞ\u0000ﻫ\u0000\n\u0000 ﺎٮ\u0000\u0000\u0000واﻟﻤﻜ\u0000  ﻃﺮٔا\u0000\u0000\n\u0000ﺎﻋﻤﻪ\u0000اﻟ\u0000  \u0000اﻟﻤﻬﺎراٮ\n\u0000 ﺎٮ\u0000اﻟﻠﻌ\nمٔا  \u0000ﻪ\u0000ﻟﻌ:  \u0000ﻪ\u0000\u0000\u0000اﻟﻌﺮ\u0000•\n\u0000ﻪ\u0000\u0000\u0000ﺮ\u0000ﻠ\u0000\u0000 ﺤ\u0000\u0000ٕا\u0000\u0000B2 (ﺎ\u0000\u0000\u0000ﻄﺎ\u0000\u0000ﺮ\u0000\u0000\u0000  ﻠﺲ\u0000 ﻣﺤ)•\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"!pip install arabic-reshaper python-bidi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T20:49:50.971635Z","iopub.execute_input":"2026-01-05T20:49:50.972039Z","iopub.status.idle":"2026-01-05T20:49:58.423603Z","shell.execute_reply.started":"2026-01-05T20:49:50.972009Z","shell.execute_reply":"2026-01-05T20:49:58.422805Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting arabic-reshaper\n  Downloading arabic_reshaper-3.0.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: python-bidi in /usr/local/lib/python3.12/dist-packages (0.6.7)\nDownloading arabic_reshaper-3.0.0-py3-none-any.whl (20 kB)\nInstalling collected packages: arabic-reshaper\nSuccessfully installed arabic-reshaper-3.0.0\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"import arabic_reshaper\nfrom bidi.algorithm import get_display\n\ndef fix_arabic(text):\n    reshaped = arabic_reshaper.reshape(text)\n    return get_display(reshaped)\n\nfixed_text = fix_arabic(arabic_text)\nprint(fixed_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T20:50:11.438873Z","iopub.execute_input":"2026-01-05T20:50:11.439612Z","iopub.status.idle":"2026-01-05T20:50:11.786123Z","shell.execute_reply.started":"2026-01-05T20:50:11.439571Z","shell.execute_reply":"2026-01-05T20:50:11.785361Z"}},"outputs":[{"name":"stdout","text":"|ﻟﺍﺮﺪ  ﺍﻜﻟﻭﺮﯽ :emanyaserr2003@gmail.com |ﺎﻬﻟﺍ :01096052095 |ﺪﻤﻟﺍﻪ :  ﻤﻟﺍەﺭﻮﺼ،  ﺮﺼﻣ\nLinkedIn | GitHub\nﺣﺮﺤﻪ  ﻡﻮﻠﻋ  ﺳﺎﺤﻟﺍٮﺎ  ﺤﻠﻪ  ﻮﻪ  ﯽ  ﺪﻟﺍﺀﺎﻛ  ﻄﺻﺍﯽﻋﺎ  ﻟﺍﻭﻢﻠﻌ  ﺍﯽﻟ  ﻭﻮﻄﺮ  ﻟﺍﺤﻣﺮ ٮﺎ  .ﻪﺳﺮﻜﻣ  ﺳﺤﻡﺍﺪ  ﺍﺭﺎﻬﻣﯽ  ﻟﺍﻪ\nﻞﺤﻟ  ﺴﻤﻟﺍﻞﻛﺎ  ﺍﻭﺴﺀﺎ  ﻝﻮﻠﺣ  ﻪﻟﺎﻌ  .ﺍﯽﻌﺳ  ﻝﻮﺼﺤﻠﻟ  ﯽﻠﻋ  ﻪﺻﺮ  ﻞﻤﻋ  ﻟﻄ  ﺍﺭﺎﻬﻣﯽ  ﻪﻤﻫﺎﺴﻤﻟﺍﻭ  ﯽ  ﺴﻣﺭﺎﻊ  ﻣەﺮﻜ  ﻟﺍﻭﻮﻤ  ﺻ ﮟﻤ \n.ﺮ  ﺩﻣﺎﯽﻜ\nﺭﻮﻟﺎﻜﺱﻮ  ﯽ  ﻡﻮﻠﻋ  ﺳﺎﺤﻟﺍٮﺎ \nﻠﻛﻪ  ﺳﺎﺤﻟﺍٮﺎ  ﻡﻮﻠﻌﻟﺍﻭ  ﺍﻣﻋﻪ،  ﺣ ﻪﻌﻣﺎ  ﻤﻟﺍەﺭﻮﺼ\nﻝﺪﻌﻣ  ﯽﻤﻛﺍﺮ : 4  ﮟﻣ 4،  ﻤﻣﺭﺎ  ﺮﻤﻪ  ﺴﻟﺍڡﺮ \n%ﻟﺍﺴﻪ  ﺍﺣ ﻟﺎﻤﻪ : 93.56\nﻟﺍەﺮ  :ﺍﻛﻮﺮ 2021  – ﻟﻮﻮ 2025\n(NTIﻣٮﺭﺪ |ﺪﻬﻌﻤﻟﺍ  ﻟﺍﯽﻣﻮ  ﻟٮﺎﺼ \nPythonﺍﺳﺎﺳٮﺎ  ﻟﺍﺤﻣﺮﻪ  ﻌﻠﻪ\nﺍﺳﺎﺳٮﺎ  ﺪﻟﺍﺀﺎﻛ  ﻄﺻﺍﯽﻋﺎ\nﺍﺲﺳ  ﺮﻟﺍﺻﺎ ﻪ  ﻠﻟﻢﻠﻌ  ﻤﻌﻟﺍ \nTensorFlowﻣﻪﻣﺪ  ﯽ  ﻟﺍﻢﻠﻌ  ﻤﻌﻟﺍ  ﻭ\nﻟﺍەﺮ  :ﺍﻋﺲﻄﺴ  – ﺳﻤﺮ 2024\nITI)ﻣٮﺭﺪ |ﺪﻬﻌﻣ  ﻜﺣﻮﻟﻮﺎ  ٮﺎﻣﻮﻠﻌﻤﻟﺍ \nﺣﺍﻭٮﺎﻤ  ﺍﻭﺎﺼﺣٮﺎ  ﺤﻟﺍﻭ ﺮ  ﺤﻟﺍﯽﻄ  ﻠﻟﻢﻠﻌ  ﺍﯽﻟ NumPyﻭ Python\nﺼﺤ ﺮ  ﺳﺍﻭﺴﻜڡﺎ  ﻟﺍﺎٮﺎ \nﻟﺍﻢﻠﻌ  ﺍﯽﻟ  ﺣﻮﻤﻟﺍﻪ  ﻋﻭﺮ  ﺣﻮﻤﻟﺍﻪ\nﻣﻪﻣﺪ  ﯽ  ﻟﺍﻢﻠﻌ  ﻤﻌﻟﺍ \nﻟﺍەﺮ  :ﻟﻮﻮ  – ﺍﻋﺲﻄﺴ 2024\nﺍﮞﺎﻤ  ﺮﺳﺎ  ﺭﺭٯ \nﺤﻠﻤﻟﺍﺺ  ﺴﻟﺍﺤﯽﺼ\nﻮﻤﻟﺍٮﻫ  ﻟﺍﻠﻌﻤﻪ\nﻟﺍﺭﺪ  ﺴﻟﺍﻭٮﺍﺩﺎﻬ  ﻬﻤﻟﺍﻪ\nﻟﺍەﺮ :  ﺍﻛﻮﺮ 2024  – ﻮﻮ 2025\nPython, TensorFlow, Scikit-learn, Keras, LangChain, Flask, FastAPI, Hugging:ﻟﺍٮﺎ  ﺴﻤﻟﺍﺤﻪﻣﺪ\nFace\nﻟﺍەﺮ :  ﺩﻤﺴﺮ 2023  – ﺍﻋﺲﻄﺴ 2024\nPython, TensorFlow, Keras, Scikit-learn, NumPy, FastAPI, Streamlit:ﻟﺍٮﺎ  ﺴﻤﻟﺍﺤﻪﻣﺪ\nﻟﺍەﺮ :  ﺩﻤﺴﺮ 2023  – ﺍﻋﺲﻄﺴ 2024\nٮﺍﺭﻭﺪﻟﺍ  ﺴﻟﺍﻭٮﺍﺩﺎﻬ  ﺍﻭﮟ\n•Coursera |ﺣﺭﺭﺍﻮﻣٮﺎ  ﻟﺍﻢﻠﻌ  ﻤﻟﺍﻪﻣﺪ\n•Coursera |ﻟﺍﻢﻠﻌ  ﺍﯽﻟ  ﺣﻮﻤﻟﺍﻪ  :ﺍﺭﺍﺪﺤ  ﻟﺍﻭﺼ \n•Kaggle |ﻭﺭﻪ  ٮﻮﺳﺎﺤﻟﺍ \n•Kaggle |ﻣﻪﻣﺪ  ﯽ  ﻟﺍﻢﻠﻌ  ﻤﻌﻟﺍ \n•Mahara-Tech |ﻟﺍﻢﻠﻌ  ﻤﻌﻟﺍ  ﻟﺍﻄﯽ\n•Python | Mahara-Techﺍﺳﺎﺳٮﺎ  ﻟﺍﺤﻣﺮﻪ  ـ\n•Mahara-Tech |ﺍﺳﺎﺳٮﺎ  ﺪﻋﺍﻮ  ﻟﺍﺎٮﺎ \nﺴﻤﻟﺍ ﺭﺎﻊ\n(Aﺴﻣﻉﻭﺮ  ﻟﺍﺤﺡﺮ | Ancient Aura\nٮﺭﻮﻃ  ﻄ ﻡﺎ  ﺻﻮٮﺎ  ﺳﺎﺤﻡﺍﺪ  ﻟﺍﺼﻪ  ﻟﺍﻭﺎﻌﻪ  ﻊﻣ  ﻣﺮﺮ  ﻣﺩﺪﻌ  ﻡﻮﺳﻮﻟﺍ  ﻭﺴﺎﻪ  ﺣ   ﻟﺍﻡﺎﻤ  ﺡﺍﺮ  ﺍﻮﻣﻊ  ﺍﺮﻪ\n.ﺀﺎ  ﯽﻠﻋ  ﺼ ٮ  ﺴﻤﻟﺍﺤﻡﺪ\n•\n•.ﻟﺼ  ﻢﻟﺎﻌﻤﻟﺍ  ﺮﺼﻤﻟﺍﻪ  ﮟﻣ  ﺭﻮﺼﻟﺍ  ﺮﻤﻟﺍﻪﻋﻮ  ﮟﻣ  ﻞ  ﺴﻤﻟﺍﺤﻡﺪ (CNNﺀﺎ  ﻭﺭﺪ  ﺩﻮﻤﺡ  ﺳﻪﻜ  ﺼﻋﻪ  ﻪ\nRetrieval-Augmented Generationﻄ  ﻭﺭٮﻮ  ﺩﺎﺤﻣﻪ  ﻡﻮﻋﺪﻣ  ﺪﻟﺎﺀﺎﻛ  ﻄﺻﺍﯽﻋﺎ  ﺳﺎﺤﻡﺍﺪ  ﻄ ﻡﺎ\n.ﻟﺪﻢ  ﺍﺣ ﺎٮﺎ  ﺩﻪ  ﺭﺎﺤﺎ  ﮟﻋ  ﺮﺼﻣ  ﻟﺍﺪﻪﻤ ((RAG\n•\n•.ﻮﻄﺮ  ﻭﺴﺮ  ﻄ  ﺣﻝﺍﻮ  ﻞﻬﺳ  ﺳﺍﺤﻡﺍﺪ  ﻠﻟﻞﻋﺎ  ﺲﻠﺴﻟﺍ  ﻊﻣ  ﻟﺍﻄ ﻡﺎ\nﺼ  ﻟﺍﻪﻣﺎﻤ  ﻣﺩﺪﻌ  ﻟﺍٮﺎ  ﺳﺎﺤﻡﺍﺪ  ﻟﺍﻢﻠﻌ  ﻤﻌﻟﺍ | GreenGo\nﻟﻮﻄﺮ  ﺳﻪﻜ  ﺼﻋﻪ  ﻪ،  ﺣ  ﺣ  ﺩﻪ 97  %ﯽ  ﺼ  ﺭﻮﺻ ResNet50ﻄ  ﻟﺍﻢﻠﻌ  ﻟﺎﻞ  ﺳﺎﺤﻡﺍﺪ\n.ﻟﺍﻪﻣﺎﻤ  ﺍﯽﻟ 12  ﻪ\n•\n•.ﺣﺭﺎ  ﻭﻄ  ﻟﺍﺩﻮﻤﺡ FastAPIﺳﺍﺤﻡﺍﺪ\n•.ﺴﺀﺎ  ﺣﺍﻭﻪﻬ  ﺴﻪﻄ Streamlitﺳﺍﺤﻡﺍﺪ\nﺴﻜﻟﺍ  ﮟﻋ  ﺣٮﺎﻄ  ﻫﺍﺮﻜﻟﺍﻪ  ﻌﻠﻟﺎﻪ  ﺮﻌﻟﺍﻪ | HateGuard\nﺤﻟﺎﻌﻣﻪ  ﻟﺍﺹﻮﺼ  ﺮﻌﻟﺍﻪ  ﺎﺭﻪﻟﺍ  ﻟﺍﺴﻜﻞ  ٮﺎﻣﻌﻟﺍﻭ  ﺍﻭڡﺮﺣ  ﻋﺮ  ﻋﺮﻤﻟﺍﻮﻪ،  ﻊﻣ  ﻄ  ﺍﺭﻪﻟﺍ  ٮﺎﻤﻠﻜﻟﺍ  ﺴﻟﺍﺎﻪﻌ  ﻟﺍﻭﻄﻊ\n.ﻟﺍﻭﻣﺮﺮ  ﻟﺍﻭﻠﺤﻞ  ﻌﻠﻟﺍﻯﻮ\n•\n•%.ﺣ  ﺣ  ﺩﻪ Bidirectional LSTM)،  78ﺎﯽ  ﺍﺤ ەﺎ LSTMﻮﻄﺮ  ﻭﺭﺪ  ﺩﻮﻤﺡ \nPython, Keras, NumPy, Bidirectional LSTM, EarlyStopping,:ﻟﺍٮﺎ  ﺴﻤﻟﺍﺤﻪﻣﺪ\nReduceLROnPlateau\nﺭﺲ  ﺤﻟﻪ  ﻡﻮﻠﻋ  ﻟﺍﺎٮﺎ | Bionic Team\nﻭﻠﺤﻞ  ﻟﺍﺎٮﺎ  ﻟﺍﻭﻢﻠﻌ  ﺍﯽﻟ Pythonﺭﺪﺲ  ﻤﻟﺍﻫﺎﻢ  ﺍﺳﺎﺳﻪ  ﻡﻮﻠﻌﻟ  ﻟﺍﺎٮﺎ،  ﺎﻤ  ﺎﻬ\nﻟﺍەﺮ  :ﺍﻛﻮﺮ 2024  – ﻮﻮ 2025\nﺭﺲ  ﺤﻟﻪ  ﻣﻮﺳﺮﻟﺍٮﺎ | CIS Team MU\nﻌﮟ  ﻡﺎﻬﻤﻟﺍ  ﻟﺼﻋ ،ﺀﺎ  ﺣﺍﺮﻣ ﻪﻌ  ﺍ،ﻢﻬﻟﺎﻤﻋ  ﺪﻢ  ﻟﺍٮﺎﻤ  ﻭﻄ ﻢ  ﺣﺍ ٮﺎﻋﺎﻤ  ﺍﻭﮟ  ﻟﻊ  ﻟﺍﻡﺪ\nﻟﺍەﺮ  :ﺩﻤﺴﺮ 2023  – ﺍﻋﺲﻄﺴ 2024\nPython, C#, HTML, CSS, Dart\nTree, List, Dictionary, Heap, Graph،ﺣﺭﺭﺍﻮﻣٮﺎ  ﻟﺍﺭﺮ ,Greedy, Divide and Conquer, Human\nFlutter, Pandas, NumPy, Matplotlib, Seaborn, TensorFlow, Keras\nﻟﺍەﺩﺎ،  ﻞﻤﻌﻟﺍ  ﺤﻟﺍ ﯽﻋﺎﻤ،  ﻟﺍﺤ  ﯽﻤﻠﻌﻟﺍ،  ٮﺍﺭﺎﻬﻣ  ﺹﺮﻌﻟﺍ  ﻟﺍﻭﺪﻢ\nﻟﺴﺤﮟ  ﻟﺍﺭﺪ  ﻣﻭﻊ  ﺍﻁﺍﺮ  ﯽ ReduceLROnPlateauﻭ (Early Stoppingﻄ  ﻟﺍﻮ  ﻤﻟﺍﺮﻜ\n.ﻟﺍﺭﺪ \n•\nﻟﺍەﺩﺎ  ﺴﻤﻟﺍﻭ ﻪﻛﺭﺎ  ﺤﻤﻟﺍﻌﻤﻪ\nٮﺍﺭﺎﻬﻤﻟﺍ \nﻌﻟٮﺎ  ﻟﺍﺤﻣﺮﻪ\nﻫﻞﻛﺎ  ﻟﺍﺎٮﺎ  ﺤﻟﺍﻭﺭﺭﺍﻮﻣٮﺎ \nﺍﺮﻃ  ﻜﻤﻟﺍﻭٮﺎ \nٮﺍﺭﺎﻬﻤﻟﺍ  ﻟﺍﻪﻤﻋﺎ\nﻌﻠﻟﺍٮﺎ \n•ﺮﻌﻟﺍﻪ  :ﻌﻟﻪ  ﺎﻣ\n•(ﺤﻣ ﺲﻠ  ﺮﺎﻄﺎ) B2ﺍﺤ ﻠﺮﻪ\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"!pip install python-docx","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T20:52:19.304649Z","iopub.execute_input":"2026-01-05T20:52:19.305090Z","iopub.status.idle":"2026-01-05T20:52:23.343313Z","shell.execute_reply.started":"2026-01-05T20:52:19.305057Z","shell.execute_reply":"2026-01-05T20:52:23.342194Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting python-docx\n  Downloading python_docx-1.2.0-py3-none-any.whl.metadata (2.0 kB)\nRequirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from python-docx) (5.4.0)\nRequirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.12/dist-packages (from python-docx) (4.15.0)\nDownloading python_docx-1.2.0-py3-none-any.whl (252 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: python-docx\nSuccessfully installed python-docx-1.2.0\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"from docx import Document\n\ndoc = Document(\"/kaggle/input/arabic-cv-eman/Eman Yaser Arabic CV.docx\")\n\nfull_text = []\n\nfor para in doc.paragraphs:\n    if para.text.strip():\n        full_text.append(para.text)\n\narabic_text = \"\\n\".join(full_text)\nprint(arabic_text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T20:53:18.121492Z","iopub.execute_input":"2026-01-05T20:53:18.122284Z","iopub.status.idle":"2026-01-05T20:53:18.337645Z","shell.execute_reply.started":"2026-01-05T20:53:18.122245Z","shell.execute_reply":"2026-01-05T20:53:18.336699Z"}},"outputs":[{"name":"stdout","text":"إيمان ياسر رزق\nالبريد الإلكتروني: emanyaserr2003@gmail.com | الهاتف: 01096052095 | المدينة: المنصورة، مصر | LinkedIn | GitHub\nالملخص الشخصي\nخريجة علوم الحاسبات بخلفية قوية في الذكاء الاصطناعي والتعلم الآلي وتطوير البرمجيات. مكرسة لاستخدام مهاراتي التقنية لحل المشاكل وإنشاء حلول فعالة. أسعى للحصول على فرصة عمل لتطبيق مهاراتي والمساهمة في مشاريع مبتكرة والنمو ضمن فريق ديناميكي.\nالمؤهلات التعليمية\nبكالوريوس في علوم الحاسبات\nكلية الحاسبات والعلوم الإعلامية، جامعة المنصورة\nمعدل تراكمي: 4 من 4، ممتاز بمرتبة الشرف\nالنسبة الإجمالية: 93.56%\nالفترة: أكتوبر 2021 – يوليو 2025\nالتدريب والشهادات المهنية\nمتدرب | المعهد القومي للاتصالات (NTI)\nأساسيات البرمجة بلغة Python\nأساسيات الذكاء الاصطناعي\nالأسس الرياضية للتعلم العميق\nمقدمة في التعلم العميق و TensorFlow\nالفترة: أغسطس – سبتمبر 2024\nمتدرب | معهد تكنولوجيا المعلومات (ITI)\nPython و NumPy والاحتمالات والإحصائيات والجبر الخطي للتعلم الآلي\nتحضير واستكشاف البيانات\nالتعلم الآلي الموجه وغير الموجه\nمقدمة في التعلم العميق\nالفترة: يوليو – أغسطس 2024\nالدورات والشهادات الأونلاين\nخوارزميات التعلم المتقدمة | Coursera\nالتعلم الآلي الموجه: الانحدار والتصنيف | Coursera\nرؤية الحاسوب | Kaggle\nمقدمة في التعلم العميق | Kaggle\nالتعلم العميق التطبيقي | Mahara-Tech\nأساسيات البرمجة بـ Python | Mahara-Tech\nأساسيات قواعد البيانات | Mahara-Tech\nالمشاريع\nAncient Aura | مشروع التخرج (A)\nالفترة: أكتوبر 2024 – يونيو 2025\nطورت نظام توصيات باستخدام التصفية التعاونية مع ترميز متعدد الوسوم وتشابه جيب التمام لاقتراح مواقع أثرية بناءً على تفضيلات المستخدم.\nبناء وتدريب نموذج شبكة عصبية تلافيفية (CNN) لتصنيف المعالم المصرية من الصور المرفوعة من قبل المستخدم.\nتطبيق روبوت محادثة مدعوم بالذكاء الاصطناعي باستخدام نظام Retrieval-Augmented Generation (RAG) لتقديم إجابات دقيقة تاريخياً عن مصر القديمة.\nتطوير ونشر تطبيق جوال سهل الاستخدام للتفاعل السلس مع النظام.\nالتقنيات المستخدمة: Python, TensorFlow, Scikit-learn, Keras, LangChain, Flask, FastAPI, Hugging Face\nGreenGo | تصنيف القمامة متعدد الفئات باستخدام التعلم العميق\nالفترة: ديسمبر 2023 – أغسطس 2024\nتطبيق التعلم بالنقل باستخدام ResNet50 لتطوير شبكة عصبية تلافيفية، حيث حققت دقة 97% في تصنيف صور القمامة إلى 12 فئة.\nاستخدام FastAPI لاختبار وتطبيق النموذج.\nاستخدام Streamlit لإنشاء واجهة بسيطة.\nالتقنيات المستخدمة: Python, TensorFlow, Keras, Scikit-learn, NumPy, FastAPI, Streamlit\nHateGuard | الكشف عن خطاب الكراهية باللغة العربية\nالفترة: ديسمبر 2023 – أغسطس 2024\nمعالجة النصوص العربية بإزالة التشكيل والعلامات والأحرف غير المرغوبة، مع تطبيق إزالة الكلمات الشائعة والتطبيع والترميز والتحليل اللغوي.\nتطوير وتدريب نموذج LSTM ثنائي الاتجاه (Bidirectional LSTM)، حيث حقق دقة 78%.\nتطبيق التوقف المبكر (Early Stopping) و ReduceLROnPlateau لتحسين التدريب ومنع الإفراط في التدريب.\nالتقنيات المستخدمة: Python, Keras, NumPy, Bidirectional LSTM, EarlyStopping, ReduceLROnPlateau\nالقيادة والمشاركة المجتمعية\nBionic Team | رئيس لجنة علوم البيانات\nتدريس المفاهيم الأساسية لعلوم البيانات، بما فيها Python وتحليل البيانات والتعلم الآلي\nالفترة: أكتوبر 2024 – يونيو 2025\nCIS Team MU | رئيس لجنة الرسوميات\nتعيين المهام للأعضاء، مراجعة أعمالهم، تقديم التقييمات وتنظيم الاجتماعات الأونلاين لتتبع التقدم\nالفترة: ديسمبر 2023 – أغسطس 2024\nالمهارات\nلغات البرمجة\nPython, C#, HTML, CSS, Dart\nهياكل البيانات والخوارزميات\nGreedy, Divide and Conquer, Huffman, خوارزميات الفرز، Tree, List, Dictionary, Heap, Graph\nالأطر والمكتبات\nFlutter, Pandas, NumPy, Matplotlib, Seaborn, TensorFlow, Keras\nالمهارات الناعمة\nالقيادة، العمل الجماعي، البحث العلمي، مهارات العرض والتقديم\nاللغات\nالعربية: لغة أم\nالإنجليزية: B2 (مجلس بريطانيا)\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"name_schema = ResponseSchema(\n    name = \"full name\",\n    description = \"اسم المرشح الكامل كما ذكر في النص\"\n)\n\nemail_schema = ResponseSchema(\n    name = \"email\",\n    description = \"ايميل المرشح في النص\"\n)\n\neducation_schema = ResponseSchema(\n    name = \"Education\",\n    description = \"قائمة تضم معلومات عن التعليم: المؤهل الدراسي، منشئة التعليم وسنة التخرج\"\n)\n\nskills_schema = ResponseSchema(\n    name = \"Skills\",\n    description = \"قائمة من مهارات المرشح سواء التقنية او الشخصية\"\n)\n\nexperience_schema = ResponseSchema(\n    name = \"Experience\",\n    description = \"قائمة من خبرات المرشح: دور المرشح في الشركة،مكان العمل وعدد سنوات الخبرة\"\n)\n\nresponse_schema_arabic = [name_schema,email_schema,education_schema,skills_schema,experience_schema]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T21:03:41.600551Z","iopub.execute_input":"2026-01-05T21:03:41.600893Z","iopub.status.idle":"2026-01-05T21:03:41.606124Z","shell.execute_reply.started":"2026-01-05T21:03:41.600864Z","shell.execute_reply":"2026-01-05T21:03:41.605418Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"output_parser_arabic = StructuredOutputParser.from_response_schemas(response_schema_arabic)\nformat_instructions_arabic = output_parser_arabic.get_format_instructions()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T21:04:08.401356Z","iopub.execute_input":"2026-01-05T21:04:08.402125Z","iopub.status.idle":"2026-01-05T21:04:08.405440Z","shell.execute_reply.started":"2026-01-05T21:04:08.402093Z","shell.execute_reply":"2026-01-05T21:04:08.404831Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"purchase_extraction_template_arabic = \"\"\"\nأنت مساعد ذكي يستخرج معلومات المرشحين من السيرة الذاتية المُرسلة إلى قسم الموارد البشرية.\n\nاستخرج اسم المرشح، وبريده الإلكتروني، ومؤهلاته العلمية، ومهاراته، وخبراته السابقة.\n\nأجب بصيغة JSON فقط كما يلي:\n{format_instructions}\n\nمثال على المدخلات:\n\nجون سميث – john.smith@email.com\nالمؤهلات العلمية: بكالوريوس علوم الحاسوب، معهد ماساتشوستس للتكنولوجيا، 2020\nالمهارات: بايثون، تعلم الآلة، تحليل البيانات\nالخبرات:\n- مهندس برمجيات في جوجل (2020–2023)\n- عالم بيانات في OpenAI (2023–حتى الآن)\n\nالآن استخرج من المدخلات التالية:\n\"{user_input}\"\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T21:04:10.380869Z","iopub.execute_input":"2026-01-05T21:04:10.381580Z","iopub.status.idle":"2026-01-05T21:04:10.385432Z","shell.execute_reply.started":"2026-01-05T21:04:10.381553Z","shell.execute_reply":"2026-01-05T21:04:10.384736Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"user_input = arabic_text\n\nprompt = PromptTemplate(\n    template=purchase_extraction_template_arabic,\n    input_variables=[\"user_input\", \"format_instructions\"]\n).format(user_input=user_input, format_instructions=format_instructions_arabic)\n\nresponse = generate_text(prompt, max_length=3000)[0]\nprint(response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T21:04:12.171232Z","iopub.execute_input":"2026-01-05T21:04:12.171616Z","iopub.status.idle":"2026-01-05T21:04:36.105114Z","shell.execute_reply.started":"2026-01-05T21:04:12.171586Z","shell.execute_reply":"2026-01-05T21:04:36.104418Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\nأنت مساعد ذكي يستخرج معلومات المرشحين من السيرة الذاتية المُرسلة إلى قسم الموارد البشرية.\n\nاستخرج اسم المرشح، وبريده الإلكتروني، ومؤهلاته العلمية، ومهاراته، وخبراته السابقة.\n\nأجب بصيغة JSON فقط كما يلي:\nThe output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n\n```json\n{\n\t\"full name\": string  // اسم المرشح الكامل كما ذكر في النص\n\t\"email\": string  // ايميل المرشح في النص\n\t\"Education\": string  // قائمة تضم معلومات عن التعليم: المؤهل الدراسي، منشئة التعليم وسنة التخرج\n\t\"Skills\": string  // قائمة من مهارات المرشح سواء التقنية او الشخصية\n\t\"Experience\": string  // قائمة من خبرات المرشح: دور المرشح في الشركة،مكان العمل وعدد سنوات الخبرة\n}\n```\n\nمثال على المدخلات:\n\nجون سميث – john.smith@email.com\nالمؤهلات العلمية: بكالوريوس علوم الحاسوب، معهد ماساتشوستس للتكنولوجيا، 2020\nالمهارات: بايثون، تعلم الآلة، تحليل البيانات\nالخبرات:\n- مهندس برمجيات في جوجل (2020–2023)\n- عالم بيانات في OpenAI (2023–حتى الآن)\n\nالآن استخرج من المدخلات التالية:\n\"إيمان ياسر رزق\nالبريد الإلكتروني: emanyaserr2003@gmail.com | الهاتف: 01096052095 | المدينة: المنصورة، مصر | LinkedIn | GitHub\nالملخص الشخصي\nخريجة علوم الحاسبات بخلفية قوية في الذكاء الاصطناعي والتعلم الآلي وتطوير البرمجيات. مكرسة لاستخدام مهاراتي التقنية لحل المشاكل وإنشاء حلول فعالة. أسعى للحصول على فرصة عمل لتطبيق مهاراتي والمساهمة في مشاريع مبتكرة والنمو ضمن فريق ديناميكي.\nالمؤهلات التعليمية\nبكالوريوس في علوم الحاسبات\nكلية الحاسبات والعلوم الإعلامية، جامعة المنصورة\nمعدل تراكمي: 4 من 4، ممتاز بمرتبة الشرف\nالنسبة الإجمالية: 93.56%\nالفترة: أكتوبر 2021 – يوليو 2025\nالتدريب والشهادات المهنية\nمتدرب | المعهد القومي للاتصالات (NTI)\nأساسيات البرمجة بلغة Python\nأساسيات الذكاء الاصطناعي\nالأسس الرياضية للتعلم العميق\nمقدمة في التعلم العميق و TensorFlow\nالفترة: أغسطس – سبتمبر 2024\nمتدرب | معهد تكنولوجيا المعلومات (ITI)\nPython و NumPy والاحتمالات والإحصائيات والجبر الخطي للتعلم الآلي\nتحضير واستكشاف البيانات\nالتعلم الآلي الموجه وغير الموجه\nمقدمة في التعلم العميق\nالفترة: يوليو – أغسطس 2024\nالدورات والشهادات الأونلاين\nخوارزميات التعلم المتقدمة | Coursera\nالتعلم الآلي الموجه: الانحدار والتصنيف | Coursera\nرؤية الحاسوب | Kaggle\nمقدمة في التعلم العميق | Kaggle\nالتعلم العميق التطبيقي | Mahara-Tech\nأساسيات البرمجة بـ Python | Mahara-Tech\nأساسيات قواعد البيانات | Mahara-Tech\nالمشاريع\nAncient Aura | مشروع التخرج (A)\nالفترة: أكتوبر 2024 – يونيو 2025\nطورت نظام توصيات باستخدام التصفية التعاونية مع ترميز متعدد الوسوم وتشابه جيب التمام لاقتراح مواقع أثرية بناءً على تفضيلات المستخدم.\nبناء وتدريب نموذج شبكة عصبية تلافيفية (CNN) لتصنيف المعالم المصرية من الصور المرفوعة من قبل المستخدم.\nتطبيق روبوت محادثة مدعوم بالذكاء الاصطناعي باستخدام نظام Retrieval-Augmented Generation (RAG) لتقديم إجابات دقيقة تاريخياً عن مصر القديمة.\nتطوير ونشر تطبيق جوال سهل الاستخدام للتفاعل السلس مع النظام.\nالتقنيات المستخدمة: Python, TensorFlow, Scikit-learn, Keras, LangChain, Flask, FastAPI, Hugging Face\nGreenGo | تصنيف القمامة متعدد الفئات باستخدام التعلم العميق\nالفترة: ديسمبر 2023 – أغسطس 2024\nتطبيق التعلم بالنقل باستخدام ResNet50 لتطوير شبكة عصبية تلافيفية، حيث حققت دقة 97% في تصنيف صور القمامة إلى 12 فئة.\nاستخدام FastAPI لاختبار وتطبيق النموذج.\nاستخدام Streamlit لإنشاء واجهة بسيطة.\nالتقنيات المستخدمة: Python, TensorFlow, Keras, Scikit-learn, NumPy, FastAPI, Streamlit\nHateGuard | الكشف عن خطاب الكراهية باللغة العربية\nالفترة: ديسمبر 2023 – أغسطس 2024\nمعالجة النصوص العربية بإزالة التشكيل والعلامات والأحرف غير المرغوبة، مع تطبيق إزالة الكلمات الشائعة والتطبيع والترميز والتحليل اللغوي.\nتطوير وتدريب نموذج LSTM ثنائي الاتجاه (Bidirectional LSTM)، حيث حقق دقة 78%.\nتطبيق التوقف المبكر (Early Stopping) و ReduceLROnPlateau لتحسين التدريب ومنع الإفراط في التدريب.\nالتقنيات المستخدمة: Python, Keras, NumPy, Bidirectional LSTM, EarlyStopping, ReduceLROnPlateau\nالقيادة والمشاركة المجتمعية\nBionic Team | رئيس لجنة علوم البيانات\nتدريس المفاهيم الأساسية لعلوم البيانات، بما فيها Python وتحليل البيانات والتعلم الآلي\nالفترة: أكتوبر 2024 – يونيو 2025\nCIS Team MU | رئيس لجنة الرسوميات\nتعيين المهام للأعضاء، مراجعة أعمالهم، تقديم التقييمات وتنظيم الاجتماعات الأونلاين لتتبع التقدم\nالفترة: ديسمبر 2023 – أغسطس 2024\nالمهارات\nلغات البرمجة\nPython, C#, HTML, CSS, Dart\nهياكل البيانات والخوارزميات\nGreedy, Divide and Conquer, Huffman, خوارزميات الفرز، Tree, List, Dictionary, Heap, Graph\nالأطر والمكتبات\nFlutter, Pandas, NumPy, Matplotlib, Seaborn, TensorFlow, Keras\nالمهارات الناعمة\nالقيادة، العمل الجماعي، البحث العلمي، مهارات العرض والتقديم\nاللغات\nالعربية: لغة أم\nالإنجليزية: B2 (مجلس بريطانيا)\"\n```\n\nJSON output:\n\n```json\n{\n\t\"full name\": \"إيمان ياسر رزق\",\n\t\"email\": \"emanyaserr2003@gmail.com\",\n\t\"Education\": \"بكالوريوس في علوم الحاسبات, كلية الحاسبات والعلوم الإعلامية, جامعة المنصورة, 2021-2025\",\n\t\"Skills\": \"Python, C#, HTML, CSS, Dart, Greedy, Divide and Conquer, Huffman, Sorting algorithms, Tree, List, Dictionary, Heap, Graph, Flutter, Pandas, NumPy, Matplotlib, Seaborn, TensorFlow, Keras, Leading, Teamwork, Research, Presentation\",\n\t\"Experience\": \"متدرب | المعهد القومي للاتصالات (NTI), متدرب | معهد تكنولوجيا المعلومات (ITI), Ancient Aura, GreenGo, HateGuard, Bionic Team, CIS Team MU\"\n}\n```\n","output_type":"stream"}],"execution_count":51},{"cell_type":"code","source":"def extract_json_block(text):\n    pattern = r'```json\\s*(.*?)\\s*```'\n    matches = re.findall(pattern, text, re.DOTALL)\n\n    return f\"```json\\n{matches[-1]}\\n```\"\n\njson_text = extract_json_block(response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T21:04:46.670808Z","iopub.execute_input":"2026-01-05T21:04:46.671553Z","iopub.status.idle":"2026-01-05T21:04:46.675402Z","shell.execute_reply.started":"2026-01-05T21:04:46.671522Z","shell.execute_reply":"2026-01-05T21:04:46.674833Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"output_data = output_parser_arabic.parse(json_text)\nprint(output_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T21:04:49.191431Z","iopub.execute_input":"2026-01-05T21:04:49.192134Z","iopub.status.idle":"2026-01-05T21:04:49.202287Z","shell.execute_reply.started":"2026-01-05T21:04:49.192103Z","shell.execute_reply":"2026-01-05T21:04:49.201544Z"}},"outputs":[{"name":"stdout","text":"{'full name': 'إيمان ياسر رزق', 'email': 'emanyaserr2003@gmail.com', 'Education': 'بكالوريوس في علوم الحاسبات, كلية الحاسبات والعلوم الإعلامية, جامعة المنصورة, 2021-2025', 'Skills': 'Python, C#, HTML, CSS, Dart, Greedy, Divide and Conquer, Huffman, Sorting algorithms, Tree, List, Dictionary, Heap, Graph, Flutter, Pandas, NumPy, Matplotlib, Seaborn, TensorFlow, Keras, Leading, Teamwork, Research, Presentation', 'Experience': 'متدرب | المعهد القومي للاتصالات (NTI), متدرب | معهد تكنولوجيا المعلومات (ITI), Ancient Aura, GreenGo, HateGuard, Bionic Team, CIS Team MU'}\n","output_type":"stream"}],"execution_count":53},{"cell_type":"code","source":"print(output_data['full name'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T21:05:16.092512Z","iopub.execute_input":"2026-01-05T21:05:16.093109Z","iopub.status.idle":"2026-01-05T21:05:16.097159Z","shell.execute_reply.started":"2026-01-05T21:05:16.093078Z","shell.execute_reply":"2026-01-05T21:05:16.096416Z"}},"outputs":[{"name":"stdout","text":"إيمان ياسر رزق\n","output_type":"stream"}],"execution_count":54},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}