{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12615002,"sourceType":"datasetVersion","datasetId":7969439}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install transformers==4.52.4","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer\nimport torch\n\nmodel_name = \"mistralai/Mistral-Nemo-Instruct-2407\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, device_map=\"auto\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def generate_text(prompt, max_length=100, num_return_sequences=1):\n    inputs = tokenizer(prompt, return_tensors=\"pt\")\n    outputs = model.generate(\n        **inputs,\n        max_length=max_length,\n        num_return_sequences=num_return_sequences,\n        do_sample=True,\n        top_k=50,\n        top_p=0.95,\n        temperature=0.7,\n    )\n    return [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"question = \"When was Andrew Samer born?\"\nanswer = generate_text(question)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(answer[0])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(answer[0])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(answer[0])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install sentence-transformers PyPDF2 faiss-cpu","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nfrom PyPDF2 import PdfReader\nimport faiss","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def extract_text_from_pdf(pdf_path):\n    reader = PdfReader(pdf_path)\n    full_text = \"\"\n    for page in reader.pages:\n        full_text += page.extract_text() + \"\\n\"\n    return full_text","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def chunk_text(text, chunk_size=500, overlap=50):\n    words = text.split()\n    chunks = []\n    for i in range(0, len(words), chunk_size - overlap):\n        chunk = \" \".join(words[i:i + chunk_size])\n        chunks.append(chunk)\n    return chunks","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def embed_chunks(chunks, model_name='sentence-transformers/all-MiniLM-L6-v2'):\n    model = SentenceTransformer(model_name)\n    embeddings = model.encode(chunks, convert_to_numpy=True)\n    return model, embeddings","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_faiss_index(embeddings):\n    dim = embeddings.shape[1]\n    index = faiss.IndexFlatL2(dim)\n    index.add(embeddings)\n    return index","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def search_index(query, model, index, chunks, k=5):\n    query_embedding = model.encode([query], convert_to_numpy=True)\n    distances, indices = index.search(query_embedding, k)\n    return [chunks[i] for i in indices[0]]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pdf_path = \"/kaggle/input/Andrew_Samer.pdf\"  \n\ntext = extract_text_from_pdf(pdf_path)\nchunks = chunk_text(text,chunk_size=50, overlap=5)\n\nmodel_embeddings, embeddings = embed_chunks(chunks)\n\n\nindex = create_faiss_index(embeddings)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"question = \"When was Andrew Samer born?\"\ntop_chunks = search_index(question, model_embeddings, index, chunks, k=3)\n\nfor i, chunk in enumerate(top_chunks, 1):\n    print(f\"\\n--- Chunk {i} ---\\n{chunk}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"chunk = top_chunks[0]\n\nprompt = f\"Answer the next question: {question} by reading the following text:{chunk}\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"answer = generate_text(prompt, max_length=700)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(answer[0])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(answer[0])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}