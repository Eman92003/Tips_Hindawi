# ğŸ¤– LLM & Generative AI Internship Projects  
**TIPS Hindawi Internship**

This repository contains the work completed during my internship at **TIPS Hindawi**, where we explored **Natural Language Processing (NLP)** , **Large Language Models (LLMs)** and **Generative AI** through hands-on, progressive weekly projects.

The internship focused on building a **strong practical understanding**, starting from basic NLP tasks and ending with **optimized models and a complete interactive interface**.

---

## ğŸ“‚ Repository Structure

```text
â”œâ”€â”€ week 2/
â”œâ”€â”€ week 3/
â”œâ”€â”€ week 4/
â”œâ”€â”€ week 5/
â””â”€â”€ README.md


Each folder represents a specific phase of the internship, with increasing complexity and depth.

---

## ğŸ—“ï¸ Weekly Breakdown

### ğŸ”¹ Week 2 â€“ Text Summarization
In this phase, we started with the fundamentals of NLP using **pre-trained transformer models**.

**What we did:**
- Implemented text summarization using Hugging Face models
- Worked with inference only (no training)
- Applied text preprocessing
- Controlled summary length and quality

**Key Takeaway:**  
Using powerful NLP models directly for fast and effective results.

---

### ğŸ”¹ Week 3 â€“ Retrieval-Augmented Generation (RAG)

This week focused on combining **information retrieval** with **language generation**.

**What we did:**
- Built a RAG pipeline
- Retrieved relevant documents based on user queries
- Injected retrieved context into the LLM
- Improved answer accuracy and reduced hallucinations

**Key Concepts:**
- Embeddings
- Vector similarity search
- Context-aware generation

---

### ğŸ”¹ Week 4 â€“ LangChain, Chains & Output Parsers

This phase focused on building **structured LLM pipelines**.

**What we did:**
- Used LangChain to manage LLM workflows
- Built Chains to connect multiple steps
- Applied Output Parsers to extract structured JSON
- Designed prompts for structured information extraction

**Key Takeaway:**  
Converting unstructured LLM outputs into reliable structured data.

---

### ğŸ”¹ Week 5 â€“ Quantization, Fine-Tuning & Deployment

The final and most advanced phase of the internship.

**What we did:**
- Applied model quantization (4-bit / 8-bit)
- Learned fine-tuning fundamentals
- Optimized models for performance and memory
- Used Ngrok to expose local APIs
- Built an interactive Streamlit interface

**Final Outcome:**  
A complete end-to-end NLP system with:
- Optimized models  
- Backend APIs  
- User-friendly web interface  

---

## ğŸ–¥ï¸ Final Result

By the end of the internship, we successfully delivered:
- Multiple NLP applications
- Optimized and deployable LLM pipelines
- A complete interactive UI for real-time testing

This project represents the full journey from **model usage â†’ optimization â†’ deployment â†’ interface**.

---

## ğŸ› ï¸ Tools & Technologies

- Python  
- PyTorch  
- Hugging Face Transformers  
- LangChain  
- FastAPI  
- Streamlit  
- Ngrok  
- Model Quantization (BitsAndBytes)

---

## ğŸ¯ Internship Outcomes

- Strong practical experience with NLP & LLMs
- Understanding real-world AI pipelines
- Hands-on deployment experience
- Building production-ready AI applications

