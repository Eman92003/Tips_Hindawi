{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 31154,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T22:30:28.190023Z",
          "iopub.execute_input": "2025-10-17T22:30:28.190759Z",
          "iopub.status.idle": "2025-10-17T22:30:28.457279Z",
          "shell.execute_reply.started": "2025-10-17T22:30:28.190733Z",
          "shell.execute_reply": "2025-10-17T22:30:28.456374Z"
        },
        "id": "RI3dB0CWW6qX"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==4.52.4"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T22:30:28.582253Z",
          "iopub.execute_input": "2025-10-17T22:30:28.582578Z",
          "iopub.status.idle": "2025-10-17T22:30:42.940005Z",
          "shell.execute_reply.started": "2025-10-17T22:30:28.582559Z",
          "shell.execute_reply": "2025-10-17T22:30:42.939094Z"
        },
        "id": "fVfA8qB-W6qa",
        "outputId": "fab04091-9227-4f7d-b5db-506e5a451996"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting transformers==4.52.4\n  Downloading transformers-4.52.4-py3-none-any.whl.metadata (38 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.4) (3.19.1)\nCollecting huggingface-hub<1.0,>=0.30.0 (from transformers==4.52.4)\n  Downloading huggingface_hub-0.35.3-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.4) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.4) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.4) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.4) (2025.9.18)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.4) (2.32.5)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.4) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.4) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.4) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.52.4) (2025.9.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.52.4) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.52.4) (1.1.10)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.52.4) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.52.4) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.52.4) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.52.4) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.52.4) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.52.4) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.52.4) (3.4.3)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.52.4) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.52.4) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.52.4) (2025.8.3)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==4.52.4) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==4.52.4) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers==4.52.4) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers==4.52.4) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers==4.52.4) (2024.2.0)\nDownloading transformers-4.52.4-py3-none-any.whl (10.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m80.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n\u001b[?25hDownloading huggingface_hub-0.35.3-py3-none-any.whl (564 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m564.3/564.3 kB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: huggingface-hub, transformers\n  Attempting uninstall: huggingface-hub\n    Found existing installation: huggingface-hub 1.0.0rc2\n    Uninstalling huggingface-hub-1.0.0rc2:\n      Successfully uninstalled huggingface-hub-1.0.0rc2\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.53.3\n    Uninstalling transformers-4.53.3:\n      Successfully uninstalled transformers-4.53.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed huggingface-hub-0.35.3 transformers-4.52.4\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get the HuggingFace Token"
      ],
      "metadata": {
        "id": "6VFcigyRW6qb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T22:31:14.393821Z",
          "iopub.execute_input": "2025-10-17T22:31:14.394356Z",
          "iopub.status.idle": "2025-10-17T22:31:14.410632Z",
          "shell.execute_reply.started": "2025-10-17T22:31:14.394337Z",
          "shell.execute_reply": "2025-10-17T22:31:14.409651Z"
        },
        "colab": {
          "referenced_widgets": [
            "da8a1ce02bd24614ba448de6a80ebbe4"
          ]
        },
        "id": "znhAXwgUW6qc",
        "outputId": "3a26914e-9db7-4b17-8c26-9ee547c79a79"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "da8a1ce02bd24614ba448de6a80ebbe4"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPT 2 (Text Generation)"
      ],
      "metadata": {
        "id": "dPgylRn-W6qd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline, set_seed\n",
        "generator = pipeline('text-generation', model='gpt2')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T22:30:42.941572Z",
          "iopub.execute_input": "2025-10-17T22:30:42.941817Z",
          "iopub.status.idle": "2025-10-17T22:31:14.393002Z",
          "shell.execute_reply.started": "2025-10-17T22:30:42.941797Z",
          "shell.execute_reply": "2025-10-17T22:31:14.392159Z"
        },
        "colab": {
          "referenced_widgets": [
            "0818b9b958d34493b8184e4b2f11be72",
            "f25465dd9e5d4f40bdd1613b59f0ba02",
            "04d9d9ff70d94167ba1490f46cc193e7",
            "8b2fc3de9ab743df9783cabafee0c2fe",
            "e4245cfbe4ec432089a32e36dd6d43bc",
            "06d22061afa644a197eaaf096e6615e1",
            "b96b3b43363c46ceb73aa2f9e5ad694f"
          ]
        },
        "id": "O3r2bt7rW6qd",
        "outputId": "89f2b35e-d6f3-4ca0-bb2d-a33c954770a7"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "2025-10-17 22:30:53.481404: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1760740253.743491      37 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1760740253.808594      37 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0818b9b958d34493b8184e4b2f11be72"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f25465dd9e5d4f40bdd1613b59f0ba02"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "04d9d9ff70d94167ba1490f46cc193e7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8b2fc3de9ab743df9783cabafee0c2fe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e4245cfbe4ec432089a32e36dd6d43bc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "06d22061afa644a197eaaf096e6615e1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b96b3b43363c46ceb73aa2f9e5ad694f"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Device set to use cuda:0\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(42)\n",
        "output = generator(\"Hello, I'm a language model,\", max_length=30, num_return_sequences=5)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T22:38:57.118246Z",
          "iopub.execute_input": "2025-10-17T22:38:57.118582Z",
          "iopub.status.idle": "2025-10-17T22:39:00.349038Z",
          "shell.execute_reply.started": "2025-10-17T22:38:57.118555Z",
          "shell.execute_reply": "2025-10-17T22:39:00.348441Z"
        },
        "id": "vAesdGW1W6qd",
        "outputId": "3e1ca988-062e-4999-8b6e-fc96554cdbc0"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nBoth `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(output[0]['generated_text'])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T22:39:04.765039Z",
          "iopub.execute_input": "2025-10-17T22:39:04.765805Z",
          "iopub.status.idle": "2025-10-17T22:39:04.769781Z",
          "shell.execute_reply.started": "2025-10-17T22:39:04.765782Z",
          "shell.execute_reply": "2025-10-17T22:39:04.768992Z"
        },
        "id": "sVcHKxq4W6qe",
        "outputId": "03180564-32fc-4087-ab20-ce413061a1f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Hello, I'm a language model, so I can write things that are easy to understand with a little bit of code. But when you think of words, it's hard to think of words that are as simple as a little word in a sentence.\n\nSo I'm going to use a little bit of code, and I'll talk a little bit about the syntax.\n\nThis is how you write your first line:\n\n$trans = new $trans [1, 2, 3, 4]; $trans -> write ( 'Hello, I'm a language model, so I can write things that are easier to understand with a little bit of code.' );\n\nThis code is pretty simple, but it really doesn't have to be. We want to write this code in a few lines, and we're going to use an expression, which is a shorthand for the literal of the language.\n\nIn this case, we're going to use a variable named trans that's a symbol. We want to write this expression as an expression, where we're going to look for a line that matches the line we want to write.\n\nThe syntax for writing a line like this is very simple:\n\n$trans = new $trans [1, 2, 3, 4]; $\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(output[1]['generated_text'])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T22:39:14.100342Z",
          "iopub.execute_input": "2025-10-17T22:39:14.100702Z",
          "iopub.status.idle": "2025-10-17T22:39:14.104791Z",
          "shell.execute_reply.started": "2025-10-17T22:39:14.100677Z",
          "shell.execute_reply": "2025-10-17T22:39:14.104138Z"
        },
        "id": "P4UWTJKsW6qe",
        "outputId": "76ad8e32-d80c-4f30-ac31-c6bd3862f979"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Hello, I'm a language model, I've had a lot of good experiences with it, I'm a native speaker. I've been working with it for almost five years.\n\nWe're working on different programming languages. I'm working on several different languages.\n\nDo I feel like I'm in a better position to work on this type of thing?\n\nNo. I don't feel like I'm in a better position to work on this type of thing. I feel like I'm in a better position to work on code that's actually good.\n\nIt's not like I'm the only person that's been able to master a language. Even if you're not a very good programmer, I'd be more inclined to be able to master that language. That's what I'm working on.\n\nDo you have any thoughts on the idea of using some of the other languages that are now out there, especially Clojure, Python, and even the Java language?\n\nNo, I don't think Clojure is a better language. It's just a better language. I don't think I've ever been able to understand it before. Clojure is a very well-developed language.\n\nI think it's fun to be able to work on other languages, and I think it\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "len(output) # 5 different results"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T22:39:19.236564Z",
          "iopub.execute_input": "2025-10-17T22:39:19.237262Z",
          "iopub.status.idle": "2025-10-17T22:39:19.242100Z",
          "shell.execute_reply.started": "2025-10-17T22:39:19.237238Z",
          "shell.execute_reply": "2025-10-17T22:39:19.241307Z"
        },
        "id": "2ZWygHo9W6qf",
        "outputId": "5426ee6c-8042-49b7-a289-74ddfbad4439"
      },
      "outputs": [
        {
          "execution_count": 12,
          "output_type": "execute_result",
          "data": {
            "text/plain": "5"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bart ('English' Summarization Model)"
      ],
      "metadata": {
        "id": "d5OSuq-IW6qf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T22:39:34.394216Z",
          "iopub.execute_input": "2025-10-17T22:39:34.394504Z",
          "iopub.status.idle": "2025-10-17T22:39:42.379785Z",
          "shell.execute_reply.started": "2025-10-17T22:39:34.394482Z",
          "shell.execute_reply": "2025-10-17T22:39:42.379176Z"
        },
        "colab": {
          "referenced_widgets": [
            "e9c1cc830755465ba575863f6114cffb",
            "83fbb2b6e289432fb60658f9c4883407",
            "705afe94a9514160a7dc8150aef00522",
            "cf3556f434ed4390bfda904bc221bfa2",
            "2c21efa89b6842e98a86b45288167aca",
            "6dd24a5e9ae74586ba9bd052fba49c41"
          ]
        },
        "id": "670RiCdtW6qf",
        "outputId": "cfbaf9b0-62a9-45dc-a8c5-1be8b2e31f2d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json: 0.00B [00:00, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e9c1cc830755465ba575863f6114cffb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "83fbb2b6e289432fb60658f9c4883407"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "705afe94a9514160a7dc8150aef00522"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "vocab.json: 0.00B [00:00, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cf3556f434ed4390bfda904bc221bfa2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "merges.txt: 0.00B [00:00, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2c21efa89b6842e98a86b45288167aca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json: 0.00B [00:00, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6dd24a5e9ae74586ba9bd052fba49c41"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Device set to use cuda:0\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "ARTICLE = \"\"\" New York (CNN)When Liana Barrientos was 23 years old, she got married in Westchester County, New York.\n",
        "A year later, she got married again in Westchester County, but to a different man and without divorcing her first husband.\n",
        "Only 18 days after that marriage, she got hitched yet again. Then, Barrientos declared \"I do\" five more times, sometimes only within two weeks of each other.\n",
        "In 2010, she married once more, this time in the Bronx. In an application for a marriage license, she stated it was her \"first and only\" marriage.\n",
        "Barrientos, now 39, is facing two criminal counts of \"offering a false instrument for filing in the first degree,\" referring to her false statements on the\n",
        "2010 marriage license application, according to court documents.\n",
        "Prosecutors said the marriages were part of an immigration scam.\n",
        "On Friday, she pleaded not guilty at State Supreme Court in the Bronx, according to her attorney, Christopher Wright, who declined to comment further.\n",
        "After leaving court, Barrientos was arrested and charged with theft of service and criminal trespass for allegedly sneaking into the New York subway through an emergency exit, said Detective\n",
        "Annette Markowski, a police spokeswoman. In total, Barrientos has been married 10 times, with nine of her marriages occurring between 1999 and 2002.\n",
        "All occurred either in Westchester County, Long Island, New Jersey or the Bronx. She is believed to still be married to four men, and at one time, she was married to eight men at once, prosecutors say.\n",
        "Prosecutors said the immigration scam involved some of her husbands, who filed for permanent residence status shortly after the marriages.\n",
        "Any divorces happened only after such filings were approved. It was unclear whether any of the men will be prosecuted.\n",
        "The case was referred to the Bronx District Attorney\\'s Office by Immigration and Customs Enforcement and the Department of Homeland Security\\'s\n",
        "Investigation Division. Seven of the men are from so-called \"red-flagged\" countries, including Egypt, Turkey, Georgia, Pakistan and Mali.\n",
        "Her eighth husband, Rashid Rajput, was deported in 2006 to his native Pakistan after an investigation by the Joint Terrorism Task Force.\n",
        "If convicted, Barrientos faces up to four years in prison.  Her next court appearance is scheduled for May 18.\n",
        "\"\"\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T22:40:11.301095Z",
          "iopub.execute_input": "2025-10-17T22:40:11.301436Z",
          "iopub.status.idle": "2025-10-17T22:40:11.306218Z",
          "shell.execute_reply.started": "2025-10-17T22:40:11.301412Z",
          "shell.execute_reply": "2025-10-17T22:40:11.305426Z"
        },
        "id": "HRMOevLcW6qf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "output = summarizer(ARTICLE, max_length=130, min_length=30, do_sample=False)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T22:40:16.095509Z",
          "iopub.execute_input": "2025-10-17T22:40:16.095823Z",
          "iopub.status.idle": "2025-10-17T22:40:17.216078Z",
          "shell.execute_reply.started": "2025-10-17T22:40:16.095800Z",
          "shell.execute_reply": "2025-10-17T22:40:17.215490Z"
        },
        "id": "4WHKawzjW6qg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "output[0]['summary_text']"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T22:40:18.984647Z",
          "iopub.execute_input": "2025-10-17T22:40:18.984919Z",
          "iopub.status.idle": "2025-10-17T22:40:18.989972Z",
          "shell.execute_reply.started": "2025-10-17T22:40:18.984899Z",
          "shell.execute_reply": "2025-10-17T22:40:18.989337Z"
        },
        "id": "jB7H1rmcW6qg",
        "outputId": "17dd2ddc-ae6e-4785-d0fa-adb2c6b4aad1"
      },
      "outputs": [
        {
          "execution_count": 16,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'Liana Barrientos, 39, is charged with two counts of \"offering a false instrument for filing in the first degree\" In total, she has been married 10 times, with nine of her marriages occurring between 1999 and 2002. She is believed to still be married to four men.'"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test on Arabic"
      ],
      "metadata": {
        "id": "ZCc9nRj2W6qg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ARTICLE = \"\"\" انا اسمي احمد وانا بحب البرمجه. انا اسمي احمد وانا بحب البرمجه. انا اسمي احمد وانا بحب البرمجه. انا اسمي احمد وانا بحب البرمجه. انا اسمي احمد وانا بحب البرمجه. انا اسمي احمد وانا بحب البرمجه. انا اسمي احمد وانا بحب البرمجه. انا اسمي احمد وانا بحب البرمجه. انا اسمي احمد وانا بحب البرمجه. انا اسمي احمد وانا بحب البرمجه. انا اسمي احمد وانا بحب البرمجه. انا اسمي احمد وانا بحب البرمجه.\n",
        "\"\"\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T22:40:46.894604Z",
          "iopub.execute_input": "2025-10-17T22:40:46.895224Z",
          "iopub.status.idle": "2025-10-17T22:40:46.898861Z",
          "shell.execute_reply.started": "2025-10-17T22:40:46.895202Z",
          "shell.execute_reply": "2025-10-17T22:40:46.898043Z"
        },
        "id": "6GzRzKVeW6qg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "output = summarizer(ARTICLE, max_length=130, min_length=30, do_sample=False)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T22:40:50.395091Z",
          "iopub.execute_input": "2025-10-17T22:40:50.395809Z",
          "iopub.status.idle": "2025-10-17T22:40:52.258046Z",
          "shell.execute_reply.started": "2025-10-17T22:40:50.395784Z",
          "shell.execute_reply": "2025-10-17T22:40:52.257223Z"
        },
        "id": "Wb5sGV8_W6qh"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T22:40:53.859919Z",
          "iopub.execute_input": "2025-10-17T22:40:53.860638Z",
          "iopub.status.idle": "2025-10-17T22:40:53.865162Z",
          "shell.execute_reply.started": "2025-10-17T22:40:53.860613Z",
          "shell.execute_reply": "2025-10-17T22:40:53.864363Z"
        },
        "id": "HcVKeqjIW6qh",
        "outputId": "2d67898e-15f2-4de1-d35a-58dabe28b270"
      },
      "outputs": [
        {
          "execution_count": 19,
          "output_type": "execute_result",
          "data": {
            "text/plain": "[{'summary_text': '   \\xa0  اسمي \\xa0احمد \\xa0\\xa0 \\xa0“اح\\xa0magnificent’ \\xa0-   ‘”’ “’”  ”” –  \\u2009”.  “\\xa0”\\xa0\\u2009“” - ”. ” – “.” ”-  ’’. \\u2009\\xa0‘’- ”, \\u2009. ‚’, ”;. “;.’\\xa0�'}]"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# mbert2mbert-arabic-text-summarization ('Arabic' Summarization)"
      ],
      "metadata": {
        "id": "Fekg1f86W6qh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install arabert"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T22:40:59.704327Z",
          "iopub.execute_input": "2025-10-17T22:40:59.704930Z",
          "iopub.status.idle": "2025-10-17T22:41:06.731930Z",
          "shell.execute_reply.started": "2025-10-17T22:40:59.704907Z",
          "shell.execute_reply": "2025-10-17T22:41:06.730999Z"
        },
        "id": "sFIHfAZJW6qh",
        "outputId": "7dbc6e33-0482-4d31-86e8-ca0e297b6acd"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Collecting arabert\n  Downloading arabert-1.0.1-py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: PyArabic in /usr/local/lib/python3.11/dist-packages (from arabert) (0.6.15)\nCollecting farasapy (from arabert)\n  Downloading farasapy-0.1.1-py3-none-any.whl.metadata (11 kB)\nCollecting emoji==1.4.2 (from arabert)\n  Downloading emoji-1.4.2.tar.gz (184 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m185.0/185.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: requests~=2.32 in /usr/local/lib/python3.11/dist-packages (from farasapy->arabert) (2.32.5)\nRequirement already satisfied: tqdm~=4.66 in /usr/local/lib/python3.11/dist-packages (from farasapy->arabert) (4.67.1)\nRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from PyArabic->arabert) (1.17.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests~=2.32->farasapy->arabert) (3.4.3)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests~=2.32->farasapy->arabert) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests~=2.32->farasapy->arabert) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests~=2.32->farasapy->arabert) (2025.8.3)\nDownloading arabert-1.0.1-py3-none-any.whl (179 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading farasapy-0.1.1-py3-none-any.whl (14 kB)\nBuilding wheels for collected packages: emoji\n  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for emoji: filename=emoji-1.4.2-py3-none-any.whl size=186456 sha256=d53e85ee04638f53d8d56701d043ae560d3a8117419e2dd4d01b564d6efc2d82\n  Stored in directory: /root/.cache/pip/wheels/94/08/b4/78657b1541bb704b088317b52429ee4016d9888fe47dbb130f\nSuccessfully built emoji\nInstalling collected packages: emoji, farasapy, arabert\n  Attempting uninstall: emoji\n    Found existing installation: emoji 2.15.0\n    Uninstalling emoji-2.15.0:\n      Successfully uninstalled emoji-2.15.0\nSuccessfully installed arabert-1.0.1 emoji-1.4.2 farasapy-0.1.1\nNote: you may need to restart the kernel to use updated packages.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
        "from arabert.preprocess import ArabertPreprocessor\n",
        "\n",
        "model_name=\"malmarjeh/mbert2mbert-arabic-text-summarization\"\n",
        "preprocessor = ArabertPreprocessor(model_name=\"\")\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "pipeline = pipeline(\"text2text-generation\",model=model,tokenizer=tokenizer)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T22:41:38.734440Z",
          "iopub.execute_input": "2025-10-17T22:41:38.734772Z",
          "iopub.status.idle": "2025-10-17T22:41:53.316780Z",
          "shell.execute_reply.started": "2025-10-17T22:41:38.734747Z",
          "shell.execute_reply": "2025-10-17T22:41:53.316166Z"
        },
        "colab": {
          "referenced_widgets": [
            "2237fec2f7304a50ba108cc67e61315a",
            "d17abad506444da294187cd84a54512d",
            "7d52c04d14804e3694f4e4843e0db65e",
            "bdfd27a6046d44a9abdb66bc2404147a",
            "13d9d1e965a74c73904bf06bd3d36dc6",
            "6cef3fb1badb468d97898b16e103f768"
          ]
        },
        "id": "9NrxIc1VW6qi",
        "outputId": "0f222829-7c66-4f79-e6e0-144e3c35e089"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/534 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2237fec2f7304a50ba108cc67e61315a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "vocab.txt: 0.00B [00:00, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d17abad506444da294187cd84a54512d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7d52c04d14804e3694f4e4843e0db65e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json: 0.00B [00:00, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bdfd27a6046d44a9abdb66bc2404147a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "pytorch_model.bin:   0%|          | 0.00/828M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "13d9d1e965a74c73904bf06bd3d36dc6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/828M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6cef3fb1badb468d97898b16e103f768"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\nThe following encoder weights were not tied to the decoder ['bert/pooler']\nThe following encoder weights were not tied to the decoder ['bert/pooler']\nThe following encoder weights were not tied to the decoder ['bert/pooler']\nDevice set to use cuda:0\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"في صباح يوم الجمعة، ذهبت ليلى مع عائلتها إلى الحديقة العامة. لعب الأطفال بالكرة بالقرب من البحيرة، بينما جلست ليلى تقرأ كتابًا عن التاريخ. بعد ذلك، تناولوا وجبة غداء خفيفة تحت ظل الأشجار، ثم عادوا إلى المنزل قبل غروب الشمس.\"\n",
        "text = preprocessor.preprocess(text)\n",
        "\n",
        "result = pipeline(text,\n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "            num_beams=3,\n",
        "            repetition_penalty=3.0,\n",
        "            max_length=200,\n",
        "            length_penalty=1.0,\n",
        "            no_repeat_ngram_size = 3)[0]['generated_text']"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T22:41:53.318116Z",
          "iopub.execute_input": "2025-10-17T22:41:53.318641Z",
          "iopub.status.idle": "2025-10-17T22:41:53.728138Z",
          "shell.execute_reply.started": "2025-10-17T22:41:53.318615Z",
          "shell.execute_reply": "2025-10-17T22:41:53.727362Z"
        },
        "id": "iV9ckJApW6qi",
        "outputId": "f48650e6-5b79-48b3-edbb-f14a617aafcb"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "Setting `pad_token_id` to `eos_token_id`:102 for open-end generation.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T22:41:53.729024Z",
          "iopub.execute_input": "2025-10-17T22:41:53.729247Z",
          "iopub.status.idle": "2025-10-17T22:41:55.260449Z",
          "shell.execute_reply.started": "2025-10-17T22:41:53.729229Z",
          "shell.execute_reply": "2025-10-17T22:41:55.259804Z"
        },
        "id": "CjcaXo9jW6qi",
        "outputId": "95c1fb54-8cff-4a36-814e-2aaadddf9e6f"
      },
      "outputs": [
        {
          "execution_count": 23,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'عائلات في الحديقة العامة تبحث عن وجبة غداء خفيفة'"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mistral (Large Language Model)"
      ],
      "metadata": {
        "id": "krKLlCDjW6qi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "model_name = \"mistralai/Mistral-Nemo-Instruct-2407\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, device_map=\"auto\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T22:31:21.047154Z",
          "iopub.execute_input": "2025-10-17T22:31:21.047444Z",
          "iopub.status.idle": "2025-10-17T22:35:48.617763Z",
          "shell.execute_reply.started": "2025-10-17T22:31:21.047424Z",
          "shell.execute_reply": "2025-10-17T22:35:48.617167Z"
        },
        "colab": {
          "referenced_widgets": [
            "34f878c0e2d24753a09ccd8e48d695da",
            "a4ab242466254411a46172325ee08776",
            "d984bd0d505b4c299926dcf8a4844b5d",
            "3dd74b73efd3469c83d317c25e211315",
            "eb9955b6c3d24f05aa2d4dc569132582",
            "b4c74d987c6c4a3e9fa293c413216a9f",
            "bcc5fe7795694f0dac0c564eccb36a39",
            "52cc09ff46e649e7ac99529ec48f6c92",
            "c5a3be4bb8044ba6acf150508795da47",
            "a5d72e6efd1846f9aa62d36853c7737b",
            "b718662c031444a188aea4ae1edf1c99",
            "d225c80504c94d74a340dc2d9f11901d",
            "37dde46818094466b103399677fb4f14"
          ]
        },
        "id": "wrZm2eEVW6qi",
        "outputId": "947fcade-9dea-46e2-f449-b3d5c1dba089"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json: 0.00B [00:00, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "34f878c0e2d24753a09ccd8e48d695da"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json: 0.00B [00:00, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a4ab242466254411a46172325ee08776"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d984bd0d505b4c299926dcf8a4844b5d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/622 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3dd74b73efd3469c83d317c25e211315"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors.index.json: 0.00B [00:00, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eb9955b6c3d24f05aa2d4dc569132582"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b4c74d987c6c4a3e9fa293c413216a9f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model-00001-of-00005.safetensors:   0%|          | 0.00/4.87G [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bcc5fe7795694f0dac0c564eccb36a39"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model-00003-of-00005.safetensors:   0%|          | 0.00/4.91G [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "52cc09ff46e649e7ac99529ec48f6c92"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model-00002-of-00005.safetensors:   0%|          | 0.00/4.91G [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c5a3be4bb8044ba6acf150508795da47"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model-00004-of-00005.safetensors:   0%|          | 0.00/4.91G [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a5d72e6efd1846f9aa62d36853c7737b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model-00005-of-00005.safetensors:   0%|          | 0.00/4.91G [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b718662c031444a188aea4ae1edf1c99"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d225c80504c94d74a340dc2d9f11901d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "37dde46818094466b103399677fb4f14"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(prompt, max_length=100, num_return_sequences=1):\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_length=max_length,\n",
        "        num_return_sequences=num_return_sequences,\n",
        "        do_sample=True,\n",
        "        top_k=50,\n",
        "        top_p=0.95,\n",
        "        temperature=0.7,\n",
        "    )\n",
        "\n",
        "    return [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T22:35:51.526019Z",
          "iopub.execute_input": "2025-10-17T22:35:51.526548Z",
          "iopub.status.idle": "2025-10-17T22:35:51.533410Z",
          "shell.execute_reply.started": "2025-10-17T22:35:51.526496Z",
          "shell.execute_reply": "2025-10-17T22:35:51.532584Z"
        },
        "id": "C7As9fhjW6qi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Give me the mcu list by released\"\n",
        "answer = generate_text(question, max_length = 300)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T22:35:51.703007Z",
          "iopub.execute_input": "2025-10-17T22:35:51.703221Z",
          "iopub.status.idle": "2025-10-17T22:36:24.129682Z",
          "shell.execute_reply.started": "2025-10-17T22:35:51.703203Z",
          "shell.execute_reply": "2025-10-17T22:36:24.128842Z"
        },
        "id": "84-M5nqKW6qi",
        "outputId": "d108ac77-75b3-4d89-9e3f-a8d665da0e31"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py:2479: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n  warnings.warn(\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(answer[0])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T22:36:24.130861Z",
          "iopub.execute_input": "2025-10-17T22:36:24.131147Z",
          "iopub.status.idle": "2025-10-17T22:36:24.135519Z",
          "shell.execute_reply.started": "2025-10-17T22:36:24.131118Z",
          "shell.execute_reply": "2025-10-17T22:36:24.134789Z"
        },
        "id": "L_3wEDdQW6qj",
        "outputId": "4d7f462e-9358-4f60-8518-09e8daa5e9f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Give me the mcu list by released date\n\ni think this is what you're looking for:\n\n1. Iron Man (2008)\n2. The Incredible Hulk (2008)\n3. Iron Man 2 (2010)\n4. Thor (2011)\n5. Captain America: The First Avenger (2011)\n6. The Avengers (2012)\n7. Iron Man 3 (2013)\n8. Thor: The Dark World (2013)\n9. Captain America: The Winter Soldier (2014)\n10. Guardians of the Galaxy (2014)\n11. Avengers: Age of Ultron (2015)\n12. Ant-Man (2015)\n13. Captain America: Civil War (2016)\n14. Doctor Strange (2016)\n15. Guardians of the Galaxy Vol. 2 (2017)\n16. Spider-Man: Homecoming (2017)\n17. Thor: Ragnarok (2017)\n18. Black Panther (2018)\n19. Avengers: Infinity War (2018)\n20. Ant-Man and the Wasp (2018)\n21. Captain Marvel (2019)\n22. Avengers: Endgame (20\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "E0huRbHcW6qj"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}