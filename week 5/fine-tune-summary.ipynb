{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T15:44:35.903063Z",
     "iopub.status.busy": "2025-11-13T15:44:35.902867Z",
     "iopub.status.idle": "2025-11-13T15:46:08.158104Z",
     "shell.execute_reply": "2025-11-13T15:46:08.157183Z",
     "shell.execute_reply.started": "2025-11-13T15:44:35.903047Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.9/116.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.6/85.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.4/77.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m93.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m102.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\n",
      "pylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\n",
      "cudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\n",
      "kaggle-environments 1.18.0 requires transformers>=4.33.1, but you have transformers 4.31.0 which is incompatible.\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\n",
      "sentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.31.0 which is incompatible.\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\n",
      "cudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q \\\n",
    "    transformers==4.31 \\\n",
    "    peft==0.5.0 \\\n",
    "    accelerate \\\n",
    "    bitsandbytes \\\n",
    "    trl==0.4.7 \\\n",
    "    datasets \\\n",
    "    evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T15:46:08.159953Z",
     "iopub.status.busy": "2025-11-13T15:46:08.159712Z",
     "iopub.status.idle": "2025-11-13T15:46:31.834106Z",
     "shell.execute_reply": "2025-11-13T15:46:31.833484Z",
     "shell.execute_reply.started": "2025-11-13T15:46:08.159929Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-13 15:46:16.297562: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1763048776.489132      48 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1763048776.545913      48 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datasets import Dataset, load_dataset\n",
    "from transformers import pipeline, set_seed\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from evaluate import load as load_metric\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **THE DAILY MAIL DATASET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T15:46:31.835223Z",
     "iopub.status.busy": "2025-11-13T15:46:31.834755Z",
     "iopub.status.idle": "2025-11-13T15:46:44.005152Z",
     "shell.execute_reply": "2025-11-13T15:46:44.004579Z",
     "shell.execute_reply.started": "2025-11-13T15:46:31.835204Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ac058a539484e9e8f9288e7935d6e13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0447f213e7047c6920d570133f6119d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "3.0.0/train-00000-of-00003.parquet:   0%|          | 0.00/257M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e0658b1dfea4335b2ed188325961866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "3.0.0/train-00001-of-00003.parquet:   0%|          | 0.00/257M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc76920da21c4baba1c38f75e33a34e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "3.0.0/train-00002-of-00003.parquet:   0%|          | 0.00/259M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bcf9e42ff4b4cdab6d97242eb625ec5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "3.0.0/validation-00000-of-00001.parquet:   0%|          | 0.00/34.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97b4ea51631f43b4a344287291f5906b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "3.0.0/test-00000-of-00001.parquet:   0%|          | 0.00/30.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6000218b1cd549b089b70a529442102d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/287113 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2500cb0e93e54cf4b9c4072c4f90b897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/13368 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3bbd43fb7d44052950c5bc39a8bab5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/11490 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\")\n",
    "\n",
    "train_data = dataset[\"train\"]\n",
    "validation_data = dataset[\"validation\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOOKING OUT FOR A SAMPLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRE PROCESSING FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SIZE_TRAIN = 1000 \n",
    "SAMPLE_SIZE_EVAL = 100 \n",
    "\n",
    "train_data = train_data.select(range(SAMPLE_SIZE_TRAIN))\n",
    "validation_data = validation_data.select(range(SAMPLE_SIZE_EVAL))\n",
    "\n",
    "print(f\"new data{len(train_data)}\")\n",
    "print(f\"new data{len(validation_data)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T16:09:57.417989Z",
     "iopub.status.busy": "2025-11-13T16:09:57.417254Z",
     "iopub.status.idle": "2025-11-13T16:09:57.422676Z",
     "shell.execute_reply": "2025-11-13T16:09:57.421877Z",
     "shell.execute_reply.started": "2025-11-13T16:09:57.417964Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def format_simple_summarization(sample):\n",
    "    return {\n",
    "        \"text\": f\"{sample['article']}\\n\\nSummary:\\n{sample['highlights']}\",\n",
    "    }\n",
    "\n",
    "def generate_instruction_dataset(data_point):\n",
    "    \n",
    "    formatted_data = format_simple_summarization(data_point)\n",
    "    \n",
    "    return {\n",
    "        \"article\": data_point[\"article\"],\n",
    "        \"highlights\": data_point[\"highlights\"],\n",
    "        \"text\": formatted_data[\"text\"] \n",
    "    }\n",
    "\n",
    "def process_dataset(data: Dataset):\n",
    "    return (\n",
    "        data.shuffle(seed=42)\n",
    "        .map(generate_instruction_dataset).remove_columns(['id'])\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Converting the `article text` and `summary` to a `prompt`:**\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "    Summarize the following conversation.\n",
    "    \n",
    "    ### Input:\n",
    "    (CNN) -- Usain Bolt rounded off the world championships Sunday by claiming his third \n",
    "    gold in Moscow as he anchored Jamaica to\n",
    "    victory in the men's 4x100m relay. The fastest man in the world charged clear of United \n",
    "    States rival Justin Gatlin as the Jamaican\n",
    "    quartet of Nesta Carter, Kemar Bailey-Cole, Nickel Ashmeade and Bolt won in 37.36 \n",
    "    seconds. The U.S finished second in 37.56 seconds \n",
    "    with Canada taking the bronze after Britain were disqualified for a faulty handover. \n",
    "    The 26-year-old Bolt has n......\n",
    "    \n",
    "\n",
    "    ### Summary:\n",
    "\n",
    "    Usain Bolt wins third gold of world championship .\n",
    "    Anchors Jamaica to 4x100m relay victory .\n",
    "    Eighth gold at the championships for Bolt .\n",
    "    Jamaica double up in women's 4x100m relay .\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns_to_remove = dataset['train'].column_names \n",
    "\n",
    "\n",
    "train_data = dataset['train'].shuffle(seed=42).select([i for i in range(1000)]).map(\n",
    "    format_simple_summarization,\n",
    "    remove_columns=columns_to_remove\n",
    ")\n",
    "\n",
    "\n",
    "validation_data = dataset['validation'].shuffle(seed=42).select([i for i in range(100)]).map(\n",
    "    format_simple_summarization,\n",
    "    remove_columns=columns_to_remove\n",
    ")\n",
    "\n",
    "test_data = dataset['test'].shuffle(seed=42).select([i for i in range(100)]) \n",
    "\n",
    "\n",
    "print(f\"size of new data{len(train_data)}\")\n",
    "print(f\"size of new data{len(validation_data)}\")\n",
    "print(f\"size of new data {len(test_data)}\")\n",
    "\n",
    "print( train_data.column_names)\n",
    "print( validation_data.column_names)\n",
    "print(test_data.column_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **THE LLAMA-2 7B MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T16:20:38.883509Z",
     "iopub.status.busy": "2025-11-13T16:20:38.882726Z",
     "iopub.status.idle": "2025-11-13T16:20:46.311727Z",
     "shell.execute_reply": "2025-11-13T16:20:46.311089Z",
     "shell.execute_reply.started": "2025-11-13T16:20:38.883484Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a95e61d5e12d4a5fb8e8c4baaeccd9dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "model_id =  \"NousResearch/Llama-2-7b-hf\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map=\"auto\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZERO-SHOT INFERENCE WITH LLAMA-2 7B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T16:30:30.218653Z",
     "iopub.status.busy": "2025-11-13T16:30:30.217991Z",
     "iopub.status.idle": "2025-11-13T16:30:45.770594Z",
     "shell.execute_reply": "2025-11-13T16:30:45.769894Z",
     "shell.execute_reply.started": "2025-11-13T16:30:30.218629Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "New Jersey Governor Chris Christie wasn't looking too presidential Tuesday night when he got into a heated debate with a veteran teacher at a town hall meeting. And now the state's largest teacher's union is calling him out for his 'bullying' behavior. 'He's always taken a very nasty and disrespectful tone with teachers and other individuals who dare to question him at these events,' Steve Wollmer of the NJ Education Association told NJ.com. 'It's the one thing that never seems to change.' Scroll Down for Video . Not being nice: New Jersey Gov Chris Christie (left) is being called a bully for the way he interacted with a teacher (Kathy Mooney, right) at a Tuesday night town hall meeting . That sentiment doesn't ring well with Christie's ambitions to run in the Republican presidential primaries next year. Tuesday night, Christie appeared at Kenilworth Town Hall to take questions from a group of citizens, when Kathy Mooney, a high school English Teacher from Roselle Park, took the microphone. Ms Mooney, who has been a teacher for 27 years, questioned Christie's motivations behind a legal settlement with oil company ExxonMobil which could have contributed drastically to the state's pension plans for teachers. Christie settled the deal for $225million, despite the fact that the state had originally asked for $8.9billion which Mooney described as 'favoring the affluent' and 'kicking state workers under the bus'. 'I know that you could have gotten more money, on the dollar,' Mooney said. 'Do you?' a defensive Christie quickly responded. 'You do know that? Really? You know that?' Mooney started to respond, but not before being cut off by the governor. A good deal? Mooney questioned Christie's decision-making behind a $225million legal settlement. The state originally wanted $8.9billion from the oil company, and Mooney says that would have had a huge impact on pensions for public employees . 'I mean: Do you know that?' Christie continued. 'I wanna know how you know that. Because you're a teacher, and you're standing in front of students every day, conveying to them, facts - things that they need to learn. So I would like to understand your analysis of how you know that in a ten year long, court case, that you have enough detail to know.' Mooney explains that she read about the deal in the newspaper and did not attend the meeting 'to be bullied'. 'You're not being bullied, because you're asking me a question, I'm going to ask you questions back,' Christie says, as he continues to dodge the issue. 'He said, \"I'm not bullying you' as he bullied her,\"' Wollmer said of the exchange. Perhaps the reason why Wollmer and his union responded sharply to Christie's town hall meeting Tuesday night, is that he blamed the union for their role in the current pension system. 'The fact is your union, over the course of time, has asked for significantly higher benefits - more expensive benefits - that your union knew the state could not afford,' Christie said Tuesday.\n",
      "\n",
      "Summary:\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "The presidential hopeful held a town hall meeting in Kenilworth on Tuesday .\n",
      "During the meeting, high school English teacher Kathy Mooney got up to ask the governor a question about pensions .\n",
      "She asked why he didn't seek a higher legal settlement in a case with ExxonMobil that would have contributed to the state's pension system .\n",
      "Christie responded by repeatedly asking how much Mooney knew about the deal instead of answering her question .\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "MODEL GENERATION - ZERO SHOT:\n",
      "New Jersey Governor Chris Christie wasn't looking too presidential Tuesday night when he got into a heated debate with a veteran teacher at a town hall meeting. And now the state's largest teacher's union is calling him out for his 'bullying' behavior. 'He's always taken a very nasty and disrespectful tone with teachers and other individuals who dare to question him at these events,' Steve Wollmer of the NJ Education Association told NJ.com. 'It's the one thing that never seems to change.' Scroll Down for Video . Not being nice: New Jersey Gov Chris Christie (left) is being called a bully for the way he interacted with a teacher (Kathy Mooney, right) at a Tuesday night town hall meeting . That sentiment doesn't ring well with Christie's ambitions to run in the Republican presidential primaries next year. Tuesday night, Christie appeared at Kenilworth Town Hall to take questions from a group of citizens, when Kathy Mooney, a high school English Teacher from Roselle Park, took the microphone. Ms Mooney, who has been a teacher for 27 years, questioned Christie's motivations behind a legal settlement with oil company ExxonMobil which could have contributed drastically to the state's pension plans for teachers. Christie settled the deal for $225million, despite the fact that the state had originally asked for $8.9billion which Mooney described as 'favoring the affluent' and 'kicking state workers under the bus'. 'I know that you could have gotten more money, on the dollar,' Mooney said. 'Do you?' a defensive Christie quickly responded. 'You do know that? Really? You know that?' Mooney started to respond, but not before being cut off by the governor. A good deal? Mooney questioned Christie's decision-making behind a $225million legal settlement. The state originally wanted $8.9billion from the oil company, and Mooney says that would have had a huge impact on pensions for public employees . 'I mean: Do you know that?' Christie continued. 'I wanna know how you know that. Because you're a teacher, and you're standing in front of students every day, conveying to them, facts - things that they need to learn. So I would like to understand your analysis of how you know that in a ten year long, court case, that you have enough detail to know.' Mooney explains that she read about the deal in the newspaper and did not attend the meeting 'to be bullied'. 'You're not being bullied, because you're asking me a question, I'm going to ask you questions back,' Christie says, as he continues to dodge the issue. 'He said, \"I'm not bullying you' as he bullied her,\"' Wollmer said of the exchange. Perhaps the reason why Wollmer and his union responded sharply to Christie's town hall meeting Tuesday night, is that he blamed the union for their role in the current pension system. 'The fact is your union, over the course of time, has asked for significantly higher benefits - more expensive benefits - that your union knew the state could not afford,' Christie said Tuesday.\n",
      "\n",
      "Summary:\n",
      "\n",
      "1. Christie is a bully.\n",
      "2. Christie is a bully.\n",
      "3. Christie is a bully.\n",
      "4. Christie is a bully.\n",
      "5. Christie is a bully.\n",
      "6. Christie is a bully.\n",
      "7. Christie is a bully.\n",
      "8. Christie is a bully.\n",
      "9. Christie is a bully.\n",
      "10. Christie is a bully\n"
     ]
    }
   ],
   "source": [
    "index = 2\n",
    "\n",
    "\n",
    "dialogue = test_data['article'][index] \n",
    "summary = test_data['highlights'][index] \n",
    "\n",
    "\n",
    "prompt = f\"{dialogue}\\n\\nSummary:\\n\" \n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors='pt')\n",
    "output = tokenizer.decode(\n",
    "    model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        max_new_tokens=100,\n",
    "    )[0],\n",
    "    skip_special_tokens=True\n",
    ")\n",
    "\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "print(dash_line)\n",
    "print(f'INPUT PROMPT:\\n{prompt}')\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')\n",
    "print(dash_line)\n",
    "print(f'MODEL GENERATION - ZERO SHOT:\\n{output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **TRAINING STEP (FINE TUNING)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T16:31:14.672822Z",
     "iopub.status.busy": "2025-11-13T16:31:14.672170Z",
     "iopub.status.idle": "2025-11-13T16:31:14.690041Z",
     "shell.execute_reply": "2025-11-13T16:31:14.689210Z",
     "shell.execute_reply.started": "2025-11-13T16:31:14.672799Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(32000, 4096, padding_idx=0)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
      "          (up_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear4bit(in_features=11008, out_features=4096, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T16:31:14.862362Z",
     "iopub.status.busy": "2025-11-13T16:31:14.862064Z",
     "iopub.status.idle": "2025-11-13T16:35:28.998616Z",
     "shell.execute_reply": "2025-11-13T16:35:28.997764Z",
     "shell.execute_reply.started": "2025-11-13T16:31:14.862340Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 16777216 || all params: 3517190144 || trainable%: 0.477006226934315\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=64,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"], #specific to Llama models.\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T16:35:29.000494Z",
     "iopub.status.busy": "2025-11-13T16:35:29.000254Z",
     "iopub.status.idle": "2025-11-13T16:35:29.004332Z",
     "shell.execute_reply": "2025-11-13T16:35:29.003706Z",
     "shell.execute_reply.started": "2025-11-13T16:35:29.000477Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T16:35:29.005397Z",
     "iopub.status.busy": "2025-11-13T16:35:29.005171Z",
     "iopub.status.idle": "2025-11-13T16:35:29.052123Z",
     "shell.execute_reply": "2025-11-13T16:35:29.051507Z",
     "shell.execute_reply.started": "2025-11-13T16:35:29.005372Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "OUTPUT_DIR = \"llama2-docsum-adapter_quick_test\" \n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    logging_steps=10,\n",
    "    learning_rate=1e-4,\n",
    "    fp16=True,\n",
    "    max_grad_norm=0.3,\n",
    "    num_train_epochs=1,  #\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=0.2,\n",
    "    warmup_ratio=0.05,\n",
    "    save_strategy=\"epoch\",\n",
    "    group_by_length=True,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    report_to=\"tensorboard\",\n",
    "    save_safetensors=True,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    seed=42,\n",
    ")\n",
    "model.config.use_cache = False  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T16:35:29.054358Z",
     "iopub.status.busy": "2025-11-13T16:35:29.054086Z",
     "iopub.status.idle": "2025-11-13T17:40:56.145059Z",
     "shell.execute_reply": "2025-11-13T17:40:56.144329Z",
     "shell.execute_reply.started": "2025-11-13T16:35:29.054342Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fee76f36ce74306b78721ddf898eeba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1608d3792bc54d0ca3669cc9bf6e35f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62/62 1:04:18, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.808200</td>\n",
       "      <td>1.778207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1.769900</td>\n",
       "      <td>1.748653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>1.707400</td>\n",
       "      <td>1.741484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>1.746500</td>\n",
       "      <td>1.739321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=62, training_loss=1.7515673983481623, metrics={'train_runtime': 3923.3, 'train_samples_per_second': 0.255, 'train_steps_per_second': 0.016, 'total_flos': 1.774786419523584e+16, 'train_loss': 1.7515673983481623, 'epoch': 0.99})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from trl import SFTTrainer\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=validation_data,\n",
    "    peft_config=lora_config,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=1024,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T17:40:56.146025Z",
     "iopub.status.busy": "2025-11-13T17:40:56.145844Z",
     "iopub.status.idle": "2025-11-13T17:40:56.150372Z",
     "shell.execute_reply": "2025-11-13T17:40:56.149651Z",
     "shell.execute_reply.started": "2025-11-13T17:40:56.146010Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Columns: ['text']\n",
      "Validation Data Columns: ['text']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"Train Data Columns:\", train_data.column_names)\n",
    "print(\"Validation Data Columns:\", validation_data.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T17:40:56.151206Z",
     "iopub.status.busy": "2025-11-13T17:40:56.151006Z",
     "iopub.status.idle": "2025-11-13T17:40:56.379550Z",
     "shell.execute_reply": "2025-11-13T17:40:56.378948Z",
     "shell.execute_reply.started": "2025-11-13T17:40:56.151186Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./peft-dialogue-summary/tokenizer_config.json',\n",
       " './peft-dialogue-summary/special_tokens_map.json',\n",
       " './peft-dialogue-summary/tokenizer.model',\n",
       " './peft-dialogue-summary/added_tokens.json',\n",
       " './peft-dialogue-summary/tokenizer.json')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_model_path=\"./peft-dialogue-summary\"\n",
    "\n",
    "trainer.model.save_pretrained(peft_model_path)\n",
    "tokenizer.save_pretrained(peft_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T17:40:56.380360Z",
     "iopub.status.busy": "2025-11-13T17:40:56.380169Z",
     "iopub.status.idle": "2025-11-13T17:40:56.398175Z",
     "shell.execute_reply": "2025-11-13T17:40:56.397627Z",
     "shell.execute_reply.started": "2025-11-13T17:40:56.380345Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(32000, 4096, padding_idx=0)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear4bit(\n",
       "                in_features=4096, out_features=4096, bias=False\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (k_proj): Linear4bit(\n",
       "                in_features=4096, out_features=4096, bias=False\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (v_proj): Linear4bit(\n",
       "                in_features=4096, out_features=4096, bias=False\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (o_proj): Linear4bit(\n",
       "                in_features=4096, out_features=4096, bias=False\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
       "              (up_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
       "              (down_proj): Linear4bit(in_features=11008, out_features=4096, bias=False)\n",
       "              (act_fn): SiLUActivation()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm()\n",
       "            (post_attention_layernorm): LlamaRMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TextStreamer\n",
    "model.config.use_cache = True\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "peft_model_dir = \"llama2-docsum-adapter_quick_test\"\n",
    "\n",
    "print(f\"{peft_model_dir}\")\n",
    "try:\n",
    "    \n",
    "    print(os.listdir(peft_model_dir))\n",
    "    \n",
    "    if 'checkpoint-63' in os.listdir(peft_model_dir):\n",
    "        print(\"Checkpoint-63:\")\n",
    "        print(os.listdir(os.path.join(peft_model_dir, 'checkpoint-63')))\n",
    "except FileNotFoundError:\n",
    "    print(f\"{peft_model_dir} there iserror \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T17:48:11.283016Z",
     "iopub.status.busy": "2025-11-13T17:48:11.282718Z",
     "iopub.status.idle": "2025-11-13T17:52:28.800415Z",
     "shell.execute_reply": "2025-11-13T17:52:28.799593Z",
     "shell.execute_reply.started": "2025-11-13T17:48:11.282993Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c090ab879064496851abeea08138790",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from peft import AutoPeftModelForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "\n",
    "\n",
    "peft_model_dir = \"llama2-docsum-adapter_quick_test/checkpoint-62\" \n",
    "\n",
    "\n",
    "trained_model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "    peft_model_dir,\n",
    "    low_cpu_mem_usage=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    load_in_4bit=True,\n",
    "    device_map=\"auto\",          \n",
    "    local_files_only=True,      \n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(peft_model_dir, local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T18:07:10.593158Z",
     "iopub.status.busy": "2025-11-13T18:07:10.592459Z",
     "iopub.status.idle": "2025-11-13T18:08:08.199547Z",
     "shell.execute_reply": "2025-11-13T18:08:08.198793Z",
     "shell.execute_reply.started": "2025-11-13T18:07:10.593134Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "(CNN)If you've been following the news lately, there are certain things you doubtless know about Mohammad Javad Zarif. He is, of course, the Iranian foreign minister. He has been U.S. Secretary of State John Kerry's opposite number in securing a breakthrough in nuclear discussions that could lead to an end to sanctions against Iran -- if the details can be worked out in the coming weeks. And he received a hero's welcome as he arrived in Iran on a sunny Friday morning. \"Long live Zarif,\" crowds chanted as his car rolled slowly down the packed street. You may well have read that he is \"polished\" and, unusually for one burdened with such weighty issues, \"jovial.\" An Internet search for \"Mohammad Javad Zarif\" and \"jovial\" yields thousands of results. He certainly has gone a long way to bring Iran in from the cold and allow it to rejoin the international community. But there are some facts about Zarif that are less well-known. Here are six: . In September 2013, Zarif tweeted \"Happy Rosh Hashanah,\" referring to the Jewish New Year. That prompted Christine Pelosi, the daughter of House Minority Leader Nancy Pelosi, to respond with a tweet of her own: \"Thanks. The New Year would be even sweeter if you would end Iran's Holocaust denial, sir.\" And, perhaps to her surprise, Pelosi got a response. \"Iran never denied it,\" Zarif tweeted back. \"The man who was perceived to be denying it is now gone. Happy New Year.\" The reference was likely to former Iranian President Mahmoud Ahmadinejad, who had left office the previous month. Zarif was nominated to be foreign minister by Ahmadinejad's successor, Hassan Rouhami. His foreign ministry notes, perhaps defensively, that \"due to the political and security conditions of the time, he decided to continue his education in the United States.\" That is another way of saying that he was outside the country during the demonstrations against the Shah of Iran, which began in 1977, and during the Iranian Revolution, which drove the shah from power in 1979. Zarif left the country in 1977, received his undergraduate degree from San Francisco State University in 1981, his master's in international relations from the University of Denver in 1984 and his doctorate from the University of Denver in 1988. Both of his children were born in the United States. The website of the Iranian Foreign Ministry, which Zarif runs, cannot even agree with itself on when he was born. The first sentence of his official biography, perhaps in a nod to the powers that be in Tehran, says Zarif was \"born to a religious traditional family in Tehran in 1959.\" Later on the same page, however, his date of birth is listed as January 8, 1960. And the Iranian Diplomacy website says he was born in in 1961 . So he is 54, 55 or maybe even 56. Whichever, he is still considerably younger than his opposite number, Kerry, who is 71. The feds investigated him over his alleged role in controlling the Alavi Foundation, a charitable organization. The U.S. Justice Department said the organization was secretly run on behalf of the Iranian government to launder money and get around U.S. sanctions. But last year, a settlement in the case, under which the foundation agreed to give a 36-story building in Manhattan along with other properties to the U.S. government, did not mention Zarif's name. Early in the Iranian Revolution, Zarif was among the students who took over the Iranian Consulate in San Francisco. The aim, says the website Iranian.com -- which cites Zarif's memoirs, titled \"Mr. Ambassador\" -- was to expel from the consulate people who were not sufficiently Islamic. Later, the website says, Zarif went to make a similar protest at the Iranian mission to the United Nations. In response, the Iranian ambassador to the United Nations offered him a job. In fact, he has now spent more time with Kerry than any other foreign minister in the world. And that amount of quality time will only increase as the two men, with help from other foreign ministers as well, try to meet a June 30 deadline for nailing down the details of the agreement they managed to outline this week in Switzerland.\n",
      "\n",
      "Summary:\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "Mohammad Javad Zarif has spent more time with John Kerry than any other foreign minister .\n",
      "He once participated in a takeover of the Iranian Consulate in San Francisco .\n",
      "The Iranian foreign minister tweets in English .\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "TRAINED MODEL GENERATED TEXT :\n",
      "Mohammad Javad Zarif is the Iranian foreign minister .\n",
      "He was born in 1959, 1960 or 1961 .\n",
      "He was a student protester during the Iranian Revolution .\n",
      "He was offered a job by the Iranian ambassador to the United Nations .\n",
      "He is now spending more time with John Kerry than any other foreign minister .\n",
      "\n",
      "\n",
      "Summary:\n",
      "Mohammad Javad Zarif is the Iranian foreign minister .\n",
      "He was born in 1959, 1960 or 1961 .\n",
      "He was a student protester during the Iranian Revolution .\n",
      "He was offered a job by the Iranian ambassador to the United Nations .\n",
      "He is now spending more time with John Kerry than any other foreign minister .\n",
      "\n",
      "\n",
      "Summary:\n",
      "Mohammad Javad Zarif is the Iranian foreign minister .\n",
      "He was born in 1959, 1960 or 1961 .\n",
      "He was a student protester during the Iranian Revolution .\n",
      "He was offered a job by the Iranian ambassador to the United Nations .\n",
      "He is now spending more time with John Kerry than any other foreign minister .\n",
      "\n",
      "\n",
      "Summary:\n",
      "Mohammad Javad Zarif is the Iranian foreign minister .\n",
      "He was born in 1959, 1960 or 1961 .\n",
      "He was a student protester during the Iranian Revolution .\n",
      "He was offered a job by the Iranian ambassador to the United Nations .\n",
      "He is now spending more time with John Kerry than any other foreign minister .\n",
      "\n",
      "\n",
      "Summary:\n",
      "Mohammad Javad Zarif is the Iranian foreign minister .\n",
      "He was born in 1959, 1960 or 1961 .\n",
      "He was a student protester during the Iranian Revolution .\n",
      "He was offered a job by the Iranian ambassador to the United Nations .\n",
      "He is now spending more time with John Kerry than any other foreign minister .\n",
      "\n",
      "\n",
      "Summary:\n",
      "Mohammad Javad Zarif is the Iranian foreign minister .\n",
      "He was born in 1959, 1960 or 1\n"
     ]
    }
   ],
   "source": [
    "index = 2 \n",
    "\n",
    "\n",
    "dialogue = dataset['test'][index]['article'] \n",
    "summary = dataset['test'][index]['highlights']\n",
    "\n",
    "\n",
    "prompt = f\"{dialogue}\\n\\nSummary:\\n\" \n",
    "\n",
    "\n",
    "input_ids = tokenizer(prompt, return_tensors='pt', truncation=True).input_ids.cuda()\n",
    "outputs = trained_model.generate(input_ids=input_ids, max_new_tokens=500)\n",
    "\n",
    "\n",
    "output = tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True)[0]\n",
    "\n",
    "\n",
    "output_summary = output[len(prompt):].strip()\n",
    "\n",
    "\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "print(dash_line)\n",
    "print(f'INPUT PROMPT:\\n{prompt}')\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')\n",
    "print(dash_line)\n",
    "print(f'TRAINED MODEL GENERATED TEXT :\\n{output_summary}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-13T17:45:13.643214Z",
     "iopub.status.idle": "2025-11-13T17:45:13.643445Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T18:18:13.489596Z",
     "iopub.status.busy": "2025-11-13T18:18:13.488774Z",
     "iopub.status.idle": "2025-11-13T18:18:34.605183Z",
     "shell.execute_reply": "2025-11-13T18:18:34.604513Z",
     "shell.execute_reply.started": "2025-11-13T18:18:13.489569Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "(CNN)If you've been following the news lately, there are certain things you doubtless know about Mohammad Javad Zarif. He is, of course, the Iranian foreign minister. He has been U.S. Secretary of State John Kerry's opposite number in securing a breakthrough in nuclear discussions that could lead to an end to sanctions against Iran -- if the details can be worked out in the coming weeks. And he received a hero's welcome as he arrived in Iran on a sunny Friday morning. \"Long live Zarif,\" crowds chanted as his car rolled slowly down the packed street. You may well have read that he is \"polished\" and, unusually for one burdened with such weighty issues, \"jovial.\" An Internet search for \"Mohammad Javad Zarif\" and \"jovial\" yields thousands of results. He certainly has gone a long way to bring Iran in from the cold and allow it to rejoin the international community. But there are some facts about Zarif that are less well-known. Here are six: . In September 2013, Zarif tweeted \"Happy Rosh Hashanah,\" referring to the Jewish New Year. That prompted Christine Pelosi, the daughter of House Minority Leader Nancy Pelosi, to respond with a tweet of her own: \"Thanks. The New Year would be even sweeter if you would end Iran's Holocaust denial, sir.\" And, perhaps to her surprise, Pelosi got a response. \"Iran never denied it,\" Zarif tweeted back. \"The man who was perceived to be denying it is now gone. Happy New Year.\" The reference was likely to former Iranian President Mahmoud Ahmadinejad, who had left office the previous month. Zarif was nominated to be foreign minister by Ahmadinejad's successor, Hassan Rouhami. His foreign ministry notes, perhaps defensively, that \"due to the political and security conditions of the time, he decided to continue his education in the United States.\" That is another way of saying that he was outside the country during the demonstrations against the Shah of Iran, which began in 1977, and during the Iranian Revolution, which drove the shah from power in 1979. Zarif left the country in 1977, received his undergraduate degree from San Francisco State University in 1981, his master's in international relations from the University of Denver in 1984 and his doctorate from the University of Denver in 1988. Both of his children were born in the United States. The website of the Iranian Foreign Ministry, which Zarif runs, cannot even agree with itself on when he was born. The first sentence of his official biography, perhaps in a nod to the powers that be in Tehran, says Zarif was \"born to a religious traditional family in Tehran in 1959.\" Later on the same page, however, his date of birth is listed as January 8, 1960. And the Iranian Diplomacy website says he was born in in 1961 . So he is 54, 55 or maybe even 56. Whichever, he is still considerably younger than his opposite number, Kerry, who is 71. The feds investigated him over his alleged role in controlling the Alavi Foundation, a charitable organization. The U.S. Justice Department said the organization was secretly run on behalf of the Iranian government to launder money and get around U.S. sanctions. But last year, a settlement in the case, under which the foundation agreed to give a 36-story building in Manhattan along with other properties to the U.S. government, did not mention Zarif's name. Early in the Iranian Revolution, Zarif was among the students who took over the Iranian Consulate in San Francisco. The aim, says the website Iranian.com -- which cites Zarif's memoirs, titled \"Mr. Ambassador\" -- was to expel from the consulate people who were not sufficiently Islamic. Later, the website says, Zarif went to make a similar protest at the Iranian mission to the United Nations. In response, the Iranian ambassador to the United Nations offered him a job. In fact, he has now spent more time with Kerry than any other foreign minister in the world. And that amount of quality time will only increase as the two men, with help from other foreign ministers as well, try to meet a June 30 deadline for nailing down the details of the agreement they managed to outline this week in Switzerland.\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "Mohammad Javad Zarif has spent more time with John Kerry than any other foreign minister .\n",
      "He once participated in a takeover of the Iranian Consulate in San Francisco .\n",
      "The Iranian foreign minister tweets in English .\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "TRAINED MODEL GENERATED SUMMARY:\n",
      "Summary:\n",
      "Zarif was educated abroad but returned home after the revolution;\n",
      "He became involved in student protests while studying in California;\n",
      "In 2007, he was named secretary of Iran's Supreme National Security Council;\n",
      "He negotiates with Western nations on their nuclear program;\n",
      "He is known for being polite and jocular despite difficult circumstances.\n",
      "\n",
      "Source: CNN . Read entire article here . Summary: Zarif was educated abroad but returned home after the revolution; He became involved in student protests while studying in California; In 2007, he was named secretary of Iran's Supreme National Security Council; He negotiates with Western nations on their nuclear program; He is\n"
     ]
    }
   ],
   "source": [
    "index = 2\n",
    "\n",
    "\n",
    "dialogue = dataset['test'][index]['article'] \n",
    "summary = dataset['test'][index]['highlights']\n",
    "\n",
    "\n",
    "prompt = f\"{dialogue}\\n\" \n",
    "\n",
    "\n",
    "input_ids = tokenizer(prompt, return_tensors='pt', truncation=True).input_ids.cuda()\n",
    "outputs = trained_model.generate(\n",
    "    input_ids=input_ids, \n",
    "    max_new_tokens=150,\n",
    "    repetition_penalty=1.2 \n",
    ")\n",
    "\n",
    "output = tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True)[0]\n",
    "\n",
    "\n",
    "output_summary = output[len(prompt):].strip()\n",
    "\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "print(dash_line)\n",
    "print(f'INPUT PROMPT:\\n{prompt}')\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')\n",
    "print(dash_line)\n",
    "print(f'TRAINED MODEL GENERATED SUMMARY:\\n{output_summary}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T18:20:27.711399Z",
     "iopub.status.busy": "2025-11-13T18:20:27.710715Z",
     "iopub.status.idle": "2025-11-13T18:20:27.715292Z",
     "shell.execute_reply": "2025-11-13T18:20:27.714421Z",
     "shell.execute_reply.started": "2025-11-13T18:20:27.711376Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "Zarif was educated abroad but returned home after the revolution;\n",
      "He became involved in student protests while studying in California;\n",
      "In 2007, he was named secretary of Iran's Supreme National Security Council;\n",
      "He negotiates with Western nations on their nuclear program;\n",
      "He is known for being polite and jocular despite difficult circumstances.\n",
      "\n",
      "Source: CNN . Read entire article here . Summary: Zarif was educated abroad but returned home after the revolution; He became involved in student protests while studying in California; In 2007, he was named secretary of Iran's Supreme National Security Council; He negotiates with Western nations on their nuclear program; He is\n"
     ]
    }
   ],
   "source": [
    "print(output_summary )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T18:23:13.405641Z",
     "iopub.status.busy": "2025-11-13T18:23:13.404928Z",
     "iopub.status.idle": "2025-11-13T18:23:30.835076Z",
     "shell.execute_reply": "2025-11-13T18:23:30.834366Z",
     "shell.execute_reply.started": "2025-11-13T18:23:13.405614Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT ARTICLE (First 200 chars):\n",
      "\n",
      "Mohamed Salah was born in a small Egyptian village called Nagrig, where football was more than a game—it was a way of dreaming beyond the dusty streets and quiet fields. From a young age, he would ru...\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "TRAINED MODEL GENERATED SUMMARY:\n",
      "When Liverpool came calling with an offer worth £34 million ($50m), Salah knew this was his chance to make history. The Reds had won five European Cups since their formation in 1892; no player has ever scored as many goals in a single season (forty) as Salah did during the 2017–18 campaign. With every goal, he became part of the club's folklore. Now, at thirty years old, he is still hungry for more glory. This book tells the story behind these achievements, revealing how Salah overcame poverty, racism, injury, and self-doubt to become one of the world'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "custom_article = \"\"\"\n",
    "Mohamed Salah was born in a small Egyptian village called Nagrig, where football was more than a game—it was a way of dreaming beyond the dusty streets and quiet fields. From a young age, he would run barefoot after a worn-out ball, imagining himself playing under bright stadium lights one day. His parents worried about his future, but Salah’s determination was stronger than anyone’s doubts. Every morning before school, he practiced his dribbling and speed, and after sunset, he stayed on the field until it was too dark to see. When he joined El Mokawloon, one of Egypt’s local clubs, his talent began to shine, but his journey was far from easy. He often took long bus rides—sometimes up to nine hours a day—to attend training, eating his meals on the road and sleeping on the way back. His coaches saw in him something rare: a hunger to prove himself. When Basel, a Swiss club, discovered him, it was the first time Salah left Egypt. He didn’t speak the language, he missed home terribly, but he kept reminding himself that his success could inspire millions back home. In Switzerland, his explosive pace and calm finishing quickly caught attention, and soon bigger clubs began to watch. Chelsea signed him, but his time there was frustrating—he barely played, struggled for confidence, and was sent out on loan. Yet Salah never lost his smile or his discipline. He used those difficult seasons to grow stronger, both mentally and physically. \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "prompt = f\"{custom_article}\\n\" \n",
    "\n",
    "\n",
    "input_ids = tokenizer(prompt, return_tensors='pt', truncation=True).input_ids.cuda()\n",
    "outputs = trained_model.generate(\n",
    "    input_ids=input_ids, \n",
    "    max_new_tokens=150, \n",
    "    repetition_penalty=1.2 \n",
    ")\n",
    "\n",
    "\n",
    "output = tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True)[0]\n",
    "output_summary = output[len(prompt):].strip()\n",
    "\n",
    "\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "print(dash_line)\n",
    "print(f'INPUT ARTICLE (First 200 chars):\\n{custom_article[:200]}...\\n')\n",
    "print(dash_line)\n",
    "print(f'TRAINED MODEL GENERATED SUMMARY:\\n{output_summary}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T18:26:15.348307Z",
     "iopub.status.busy": "2025-11-13T18:26:15.348008Z",
     "iopub.status.idle": "2025-11-13T18:26:15.352775Z",
     "shell.execute_reply": "2025-11-13T18:26:15.351947Z",
     "shell.execute_reply.started": "2025-11-13T18:26:15.348284Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When Liverpool came calling with an offer worth £34 million ($50m), Salah knew this was his chance to make history. The Reds had won five European Cups since their formation in 1892; no player has ever scored as many goals in a single season (forty) as Salah did during the 2017–18 campaign. With every goal, he became part of the club's folklore. Now, at thirty years old, he is still hungry for more glory. This book tells the story behind these achievements, revealing how Salah overcame poverty, racism, injury, and self-doubt to become one of the world'\n"
     ]
    }
   ],
   "source": [
    "print(output_summary )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T16:20:46.402865Z",
     "iopub.status.busy": "2025-11-13T16:20:46.402639Z",
     "iopub.status.idle": "2025-11-13T16:20:46.753617Z",
     "shell.execute_reply": "2025-11-13T16:20:46.752686Z",
     "shell.execute_reply.started": "2025-11-13T16:20:46.402847Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\tzip warning: name not matched: llama2-docsum-adapter_quick_test/checkpoint-62\n",
      "\n",
      "zip error: Nothing to do! (try: zip -r model_weights.zip . -i llama2-docsum-adapter_quick_test/checkpoint-62)\n"
     ]
    }
   ],
   "source": [
    "!zip -r model_weights.zip llama2-docsum-adapter_quick_test/checkpoint-62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4221454,
     "sourceId": 7280730,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
